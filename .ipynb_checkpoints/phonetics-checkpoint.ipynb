{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-87022cfd8a39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstringdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyphonetics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSoundex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import Word, TextBlob\n",
    "import stringdist\n",
    "import numpy as np\n",
    "from pyphonetics import Soundex\n",
    "from nltk.corpus import words as nltk_words\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Spelling</th>\n",
       "      <th>Level</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>favorite</td>\n",
       "      <td>favtit</td>\n",
       "      <td>Early Within Word Pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>throw</td>\n",
       "      <td>thow</td>\n",
       "      <td>Early Within Word Pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>catch</td>\n",
       "      <td>cach</td>\n",
       "      <td>Early Within Word Pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>touchdown</td>\n",
       "      <td>tuchdone</td>\n",
       "      <td>Early Within Word Pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dance</td>\n",
       "      <td>dans</td>\n",
       "      <td>Early Within Word Pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target  Spelling                      Level Grade Unnamed: 6\n",
       "0   favorite    favtit  Early Within Word Pattern     1        NaN\n",
       "1      throw      thow  Early Within Word Pattern     1        NaN\n",
       "2      catch      cach  Early Within Word Pattern     1        NaN\n",
       "3  touchdown  tuchdone  Early Within Word Pattern     1        NaN\n",
       "4      dance      dans  Early Within Word Pattern     1        NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks = pd.read_csv('data/kidsspellingv2.csv')\n",
    "ks = ks.drop(['Code', 'Semester'], axis=1)\n",
    "ks = ks.dropna(subset=['Target', 'Spelling'])\n",
    "ks[\"Target\"] = ks.Target.apply(lambda x: x.strip())\n",
    "ks[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1358"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = pd.read_csv('data/word_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_list(list):\n",
    "    total = 0\n",
    "    for el in list:\n",
    "        if el:\n",
    "            total = total + 1\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein distance for each spelling\n",
    "ks[\"l_dist\"] = ks.apply(lambda x: stringdist.levenshtein(x['Target'], x['Spelling']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5228276877761414"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How often the Levenshtein distance is less than two\n",
    "distance_less_than_two = []\n",
    "for distance in ks[\"l_dist\"]:\n",
    "    distance_less_than_two.append(distance <= 1)\n",
    "sum(distance_less_than_two)/len(distance_less_than_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob Single correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top correction from textblob\n",
    "ks[\"textblob_correct\"] = ks.Spelling.apply(lambda x : Word(x).correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2599410898379971"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How often correction is correct\n",
    "correct = []\n",
    "for target, correction in zip(ks[\"Target\"], ks[\"textblob_correct\"]):\n",
    "    correct.append(target == correction)\n",
    "\n",
    "sum_list(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextBlob top 5 suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 suggestions from textblob\n",
    "ks[\"textblob_suggestions\"] = ks.Spelling.apply(lambda x: Word(x).spellcheck()[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks[\"textblob_suggestions\"] = ks.textblob_suggestions.apply(lambda x: [word[0] for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43519882179675995"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How often the correct word is found in the suggestions\n",
    "correct = []\n",
    "for target, suggestions in zip(ks[\"Target\"], ks[\"textblob_suggestions\"]):\n",
    "    correct.append(target in suggestions)\n",
    "    \n",
    "sum_list(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoundEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundex = Soundex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('T235', 'T235')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soundex.phonetics('touchdown'), soundex.phonetics('tuchdone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundex_dict = {}\n",
    "for word in word_freq['word']:\n",
    "    word = str(word).lower()\n",
    "    try:\n",
    "        word_phone = soundex.phonetics(word)\n",
    "    except:\n",
    "        continue\n",
    "    if word_phone in soundex_dict:\n",
    "        soundex_dict[word_phone].append(word)\n",
    "    else:\n",
    "        soundex_dict[word_phone] = [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.800150829562595"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_freq)/len(soundex_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759941089837997"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#soundex_dict[soundex.phonetics('tuchdone')]\n",
    "correct = []\n",
    "for target, spelling in zip(ks[\"Target\"], ks[\"Spelling\"]):\n",
    "    spelling_phone = soundex.phonetics(spelling)\n",
    "    if spelling_phone in soundex_dict:\n",
    "        correct.append(target in soundex_dict[spelling_phone])\n",
    "    else:\n",
    "        correct.append(False)\n",
    "        \n",
    "sum_list(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaphones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1DN\n",
      "T1DN\n"
     ]
    }
   ],
   "source": [
    "rules = [\n",
    "            (r'[^a-z]', r''),\n",
    "            (r'([bcdfhjklmnpqrstvwxyz])\\1+', r'\\1'),\n",
    "            (r'ck', r'K'),\n",
    "            (r'^ocea', r'A2'),\n",
    "            (r'^ae', r'A'),\n",
    "            (r'^[aeiou]+', r'A'),\n",
    "            (r'^[gkp]n', r'N'),\n",
    "            (r'^wr', r'R'),\n",
    "            (r'^x', r'S'),\n",
    "            (r'^wh', r'W'),\n",
    "            (r'^w', r'W'),\n",
    "            (r'^gh', r'G'),\n",
    "            (r'mb$', r'M'),\n",
    "            #(r'(nc)e$', r'NS'),\n",
    "            #(r'([aeiou][^aeiou])e$', r'\\1'),\n",
    "            #(r'(ng|st|pl|bl|tt|rs|cl)e$', r'\\1'),\n",
    "            (r'(?!^)sch', r'SK'),\n",
    "            (r'th', r'0'),\n",
    "            (r'^y', r'Y'),\n",
    "            (r't?ch',r'1'),\n",
    "            (r't?sh', r'2'),\n",
    "            (r'c(?=ia|io)', r'2'),\n",
    "            (r'ture$', r'1R'),\n",
    "            (r'[st](?=i[ao])', r'2'),\n",
    "            (r's?c(?=[iey])', r'S'),\n",
    "            (r'[q]', r'Q'),\n",
    "            (r'[c]', r'K'),\n",
    "            (r'dg(?=[iey])', r'J'),\n",
    "            (r'd', r'D'),\n",
    "            (r'g(?=h[^aeiou])', r''),\n",
    "            #(r'gh$', r''),\n",
    "            (r'[y]$', r'A'),\n",
    "            (r'gn(ed)?', r'N'),\n",
    "            (r'([^g]|^)g(?=[iey])', r'\\1G'),\n",
    "            (r'g+', r'G'),\n",
    "            (r'ph', r'F'),\n",
    "            (r'([aeiou])h(?=\\b|[^aeiou])', r'\\1'),\n",
    "            (r'[wy](?![aeiou])', r''),\n",
    "            (r'[aeiou]w', r''),\n",
    "            #(r'x', r'KS'),\n",
    "            (r'z', r'S'),\n",
    "            (r'v', r'V'),\n",
    "            (r'y', r''),\n",
    "            #(r'([aiou]+$)', r'A'),\n",
    "            #(r'([aeiou]+)', r'A')\n",
    "            (r'(?!^)[aeiou]+', r''),\n",
    "        ]\n",
    "\n",
    "def mphone(word):\n",
    "    code = word.lower()\n",
    "    for rule in rules:\n",
    "        code = re.sub(rule[0], rule[1], code)\n",
    "    return code.upper()\n",
    "\n",
    "print(mphone('tuchdone'))\n",
    "print(mphone('touchdown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaphone_dict = {}\n",
    "for word in word_freq['word']:\n",
    "    word = str(word).lower()\n",
    "    try:\n",
    "        word_phone = mphone(word)\n",
    "    except:\n",
    "        continue\n",
    "    if word_phone in metaphone_dict:\n",
    "        metaphone_dict[word_phone].append(word)\n",
    "    else:\n",
    "        metaphone_dict[word_phone] = [word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.506786378143303"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_freq)/len(metaphone_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7253313696612665"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how often does the mispelling metaphone match the target spelling metaphone?\n",
    "correct = []\n",
    "for target, spelling in zip(ks[\"Target\"], ks[\"Spelling\"]):\n",
    "    spelling_phone = mphone(spelling)\n",
    "    if spelling_phone in metaphone_dict:\n",
    "        correct.append(target in metaphone_dict[spelling_phone])\n",
    "    else:\n",
    "        correct.append(False)\n",
    "        \n",
    "sum_list(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance_1(word):\n",
    "    word = word.lower()\n",
    "    letters = list('abc1dfghjklmnpqrs2t0vwxyz')\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes = [L + R[1:] for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "    inserts = [L + c + R for L, R in splits for c in letters]\n",
    "    return set(transposes + deletes + replaces + inserts)\n",
    "\n",
    "def priority_replaces(word):\n",
    "    priorities = {'1':['2'],'2':['1'], 'b':['p'], 'c':['s','k','1'], 'd':['t'], 'g':['j'], 'j':['g'], 'k':['q'], 'm':['n'], 'n':['m'], 'p':['b'], 'q':['k'], 's':['c','2'], 't':['d'], 'x':['s','c','1','2']}\n",
    "    word = word.lower()\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    replaces = [L + c + R[1:] for L, R in splits if R and R[0] in priorities for c in priorities[R[0]]]\n",
    "    return replaces\n",
    "    \n",
    "def priority_edits(word):\n",
    "    word = word.lower()\n",
    "    letters = list('abc1dfghjklmnpqrs2t0vwxyz')\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes = [L + R[1:] for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
    "    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
    "    inserts = [L + c + R for L, R in splits for c in letters]\n",
    "    return set(replaces+ inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(x):\n",
    "    return word_freq.at[x.upper(), 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metaphone_suggestions(word, count):\n",
    "    spelling_phone = mphone(word)\n",
    "    suggestions = []\n",
    "    if spelling_phone in metaphone_dict:\n",
    "        suggestions.extend(metaphone_dict[spelling_phone])\n",
    "    #suggestions.sort(key=lambda x: stringdist.levenshtein_norm(x, word))\n",
    "    \n",
    "    #priority_suggestions = []\n",
    "    #for pword in priority_edits(spelling_phone):\n",
    "    #    if pword.upper() in metaphone_dict:\n",
    "    #        priority_suggestions.extend(metaphone_dict[pword.upper()])\n",
    "    #priority_suggestions.sort(key=lambda x: stringdist.levenshtein_norm(x, word))\n",
    "    #suggestions.extend(priority_suggestions)\n",
    "    \n",
    "    \n",
    "    additional_suggestions = []\n",
    "    for eword in edit_distance_1(spelling_phone):\n",
    "        if eword.upper() in metaphone_dict:\n",
    "            additional_suggestions.extend(metaphone_dict[eword.upper()])\n",
    "    additional_suggestions.sort(key=lambda x: stringdist.levenshtein_norm(x, word))\n",
    "    #suggestions.sort(key=lambda x: stringdist.levenshtein_norm(x, word))\n",
    "    suggestions.extend(additional_suggestions)\n",
    "    \n",
    "    #return list(dict.fromkeys(suggestions))[0:5]\n",
    "    suggestions = [sug[0].upper() + sug[1:] if word[0].upper() == word[0] else sug for sug in list(dict.fromkeys(suggestions)) if len(sug) > 1]\n",
    "    return suggestions[:count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new', 'no', 'now', 'know', 'ne']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaphone_suggestions('now',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks[\"metaphone_suggestions\"] = ks.Spelling.apply(lambda x: metaphone_suggestions(x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Spelling</th>\n",
       "      <th>Level</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>l_dist</th>\n",
       "      <th>textblob_correct</th>\n",
       "      <th>textblob_suggestions</th>\n",
       "      <th>metaphone_suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>favorite</td>\n",
       "      <td>favtit</td>\n",
       "      <td>Early Within Word Pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>fait</td>\n",
       "      <td>[fait]</td>\n",
       "      <td>[favorite, favourite]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>throw</td>\n",
       "      <td>thow</td>\n",
       "      <td>Early Within Word Pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>how</td>\n",
       "      <td>[how, show, throw, thou, thaw]</td>\n",
       "      <td>[the, thou, thaw, throw, show]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>catch</td>\n",
       "      <td>cach</td>\n",
       "      <td>Early Within Word Pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>each</td>\n",
       "      <td>[each, catch, coach, cash]</td>\n",
       "      <td>[coach, catch, cache, couch, ketch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>touchdown</td>\n",
       "      <td>tuchdone</td>\n",
       "      <td>Early Within Word Pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>tuchdone</td>\n",
       "      <td>[tuchdone]</td>\n",
       "      <td>[touchdown, touchdowns, techno, tendon, trodden]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dance</td>\n",
       "      <td>dans</td>\n",
       "      <td>Early Within Word Pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>dans</td>\n",
       "      <td>[dans]</td>\n",
       "      <td>[dance, dennis, dense, downs, diagnose]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target  Spelling                      Level Grade Unnamed: 6  l_dist  \\\n",
       "0   favorite    favtit  Early Within Word Pattern     1        NaN       3   \n",
       "1      throw      thow  Early Within Word Pattern     1        NaN       1   \n",
       "2      catch      cach  Early Within Word Pattern     1        NaN       1   \n",
       "3  touchdown  tuchdone  Early Within Word Pattern     1        NaN       3   \n",
       "4      dance      dans  Early Within Word Pattern     1        NaN       2   \n",
       "\n",
       "  textblob_correct            textblob_suggestions  \\\n",
       "0             fait                          [fait]   \n",
       "1              how  [how, show, throw, thou, thaw]   \n",
       "2             each      [each, catch, coach, cash]   \n",
       "3         tuchdone                      [tuchdone]   \n",
       "4             dans                          [dans]   \n",
       "\n",
       "                              metaphone_suggestions  \n",
       "0                             [favorite, favourite]  \n",
       "1                    [the, thou, thaw, throw, show]  \n",
       "2               [coach, catch, cache, couch, ketch]  \n",
       "3  [touchdown, touchdowns, techno, tendon, trodden]  \n",
       "4           [dance, dennis, dense, downs, diagnose]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(950, 408)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dev, test = train_test_split(ks, test_size=0.3)\n",
    "#dev.to_pickle(\"./dev.pkl\")\n",
    "#test.to_pickle(\"./test.pkl\")\n",
    "dev = pd.read_pickle(\"./dev.pkl\")\n",
    "test = pd.read_pickle(\"./test.pkl\")\n",
    "len(dev), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Spelling</th>\n",
       "      <th>l_dist</th>\n",
       "      <th>textblob_correct</th>\n",
       "      <th>textblob_suggestions</th>\n",
       "      <th>metaphone_suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>games</td>\n",
       "      <td>gams</td>\n",
       "      <td>1</td>\n",
       "      <td>game</td>\n",
       "      <td>[game, gas, gems, gums, games]</td>\n",
       "      <td>[games, gems, gyms, gums, grams]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>following</td>\n",
       "      <td>fouling</td>\n",
       "      <td>3</td>\n",
       "      <td>feeling</td>\n",
       "      <td>[feeling, forming, falling, filling, failing]</td>\n",
       "      <td>[following, feeling, flying, filing, falling]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>friends</td>\n",
       "      <td>frinds</td>\n",
       "      <td>1</td>\n",
       "      <td>friends</td>\n",
       "      <td>[friends, finds]</td>\n",
       "      <td>[friends, fronds, grinds, finds, forints]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>through</td>\n",
       "      <td>though</td>\n",
       "      <td>1</td>\n",
       "      <td>though</td>\n",
       "      <td>[though]</td>\n",
       "      <td>[though, thigh, through, tough, thorough]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>chocolate</td>\n",
       "      <td>chokelet</td>\n",
       "      <td>4</td>\n",
       "      <td>chokelet</td>\n",
       "      <td>[chokelet]</td>\n",
       "      <td>[chocolate, collet, chalet, booklet, chaplet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>with</td>\n",
       "      <td>wheth</td>\n",
       "      <td>2</td>\n",
       "      <td>wyeth</td>\n",
       "      <td>[wyeth]</td>\n",
       "      <td>[with, whet, whether, sheath, wreath]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>some</td>\n",
       "      <td>sum</td>\n",
       "      <td>2</td>\n",
       "      <td>sum</td>\n",
       "      <td>[sum]</td>\n",
       "      <td>[some, same, seem, zoom, sam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>cookie</td>\n",
       "      <td>coockie</td>\n",
       "      <td>1</td>\n",
       "      <td>coockie</td>\n",
       "      <td>[coockie]</td>\n",
       "      <td>[cock, cook, cake, kick, cookie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>climbed</td>\n",
       "      <td>clamed</td>\n",
       "      <td>2</td>\n",
       "      <td>claimed</td>\n",
       "      <td>[claimed, blamed, flamed, clamped, calmed]</td>\n",
       "      <td>[claimed, calmed, clamped, flamed, clawed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>breathe</td>\n",
       "      <td>breevu</td>\n",
       "      <td>4</td>\n",
       "      <td>breeze</td>\n",
       "      <td>[breeze, breed, breech, breezy, breeds]</td>\n",
       "      <td>[brave, bravo, brava, breeze, breech]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>traveling</td>\n",
       "      <td>travelling</td>\n",
       "      <td>1</td>\n",
       "      <td>travelling</td>\n",
       "      <td>[travelling]</td>\n",
       "      <td>[traveling, travelling, revealing, trailing, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>taking</td>\n",
       "      <td>takeing</td>\n",
       "      <td>1</td>\n",
       "      <td>taking</td>\n",
       "      <td>[taking]</td>\n",
       "      <td>[taking, ticking, tacking, tucking, tackling]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>because</td>\n",
       "      <td>becus</td>\n",
       "      <td>2</td>\n",
       "      <td>because</td>\n",
       "      <td>[because, begun, bells, focus, bees]</td>\n",
       "      <td>[books, because, bikes, bucks, backs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Johnson</td>\n",
       "      <td>Jonsun</td>\n",
       "      <td>2</td>\n",
       "      <td>Consul</td>\n",
       "      <td>[Consul]</td>\n",
       "      <td>[Johnson, Consign, Monsoon, Johnsons, Consignee]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>of</td>\n",
       "      <td>ove</td>\n",
       "      <td>2</td>\n",
       "      <td>one</td>\n",
       "      <td>[one, over, love, ve, move]</td>\n",
       "      <td>[i've, eve, hove, oven, over]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>running</td>\n",
       "      <td>raning</td>\n",
       "      <td>2</td>\n",
       "      <td>ranging</td>\n",
       "      <td>[ranging, raging, racing, waning, raining]</td>\n",
       "      <td>[running, raining, renewing, ruining, reigning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>dollar</td>\n",
       "      <td>dolr</td>\n",
       "      <td>2</td>\n",
       "      <td>door</td>\n",
       "      <td>[door, doll, dorr, dole]</td>\n",
       "      <td>[dollar, dealer, delaware, doll, dol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>me</td>\n",
       "      <td>mi</td>\n",
       "      <td>2</td>\n",
       "      <td>mid</td>\n",
       "      <td>[mid, mix, mi, mio, min]</td>\n",
       "      <td>[me, ma, mm, mi, mo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>Texas</td>\n",
       "      <td>texes</td>\n",
       "      <td>2</td>\n",
       "      <td>texas</td>\n",
       "      <td>[texas, taxes, texts, teres, sexes]</td>\n",
       "      <td>[texas, taxes, taxis, tees, sexes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>with</td>\n",
       "      <td>whith</td>\n",
       "      <td>1</td>\n",
       "      <td>with</td>\n",
       "      <td>[with, which, white, whit]</td>\n",
       "      <td>[with, white, whit, which, whither]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>cousin</td>\n",
       "      <td>cosen</td>\n",
       "      <td>2</td>\n",
       "      <td>chosen</td>\n",
       "      <td>[chosen, posen]</td>\n",
       "      <td>[casino, cuisine, cousin, cosine, casein]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>cool</td>\n",
       "      <td>coll</td>\n",
       "      <td>1</td>\n",
       "      <td>cold</td>\n",
       "      <td>[cold, call, coal, toll, roll]</td>\n",
       "      <td>[call, cool, kill, coal, cole]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>all</td>\n",
       "      <td>oll</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>[all, old, ll, ill, oil]</td>\n",
       "      <td>[all, i'll, al, oil, allow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>laboratory</td>\n",
       "      <td>labartory</td>\n",
       "      <td>2</td>\n",
       "      <td>laboratory</td>\n",
       "      <td>[laboratory]</td>\n",
       "      <td>[laboratory, liberators, laboratories, liberat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>carrot</td>\n",
       "      <td>carit</td>\n",
       "      <td>2</td>\n",
       "      <td>cart</td>\n",
       "      <td>[cart, caret]</td>\n",
       "      <td>[cart, create, court, carat, karate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>some</td>\n",
       "      <td>som</td>\n",
       "      <td>1</td>\n",
       "      <td>so</td>\n",
       "      <td>[so, some, son, sum, sob]</td>\n",
       "      <td>[some, same, seem, zoom, sam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>walking</td>\n",
       "      <td>woking</td>\n",
       "      <td>2</td>\n",
       "      <td>working</td>\n",
       "      <td>[working, waking, joking, wooing, poking]</td>\n",
       "      <td>[waking, whacking, working, joking, wooing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>they</td>\n",
       "      <td>thay</td>\n",
       "      <td>1</td>\n",
       "      <td>that</td>\n",
       "      <td>[that, they, than, thy, hay]</td>\n",
       "      <td>[they, chay, hay, than, that]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>time</td>\n",
       "      <td>tim</td>\n",
       "      <td>1</td>\n",
       "      <td>tim</td>\n",
       "      <td>[tim]</td>\n",
       "      <td>[time, team, tom, tim, tome]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>first</td>\n",
       "      <td>frist</td>\n",
       "      <td>2</td>\n",
       "      <td>first</td>\n",
       "      <td>[first, wrist, frost, fist, grist]</td>\n",
       "      <td>[first, forest, frost, foresight, fairest]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>happened</td>\n",
       "      <td>hapened</td>\n",
       "      <td>1</td>\n",
       "      <td>happened</td>\n",
       "      <td>[happened]</td>\n",
       "      <td>[happened, ripened, opened, reopened, deepened]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>classrooms</td>\n",
       "      <td>clasrums</td>\n",
       "      <td>3</td>\n",
       "      <td>clasrums</td>\n",
       "      <td>[clasrums]</td>\n",
       "      <td>[classrooms, classroom, closures, kilograms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>science</td>\n",
       "      <td>sience</td>\n",
       "      <td>1</td>\n",
       "      <td>since</td>\n",
       "      <td>[since, silence, science, spence]</td>\n",
       "      <td>[since, science, sense, signs, scenes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>would</td>\n",
       "      <td>whoud</td>\n",
       "      <td>2</td>\n",
       "      <td>who</td>\n",
       "      <td>[who, would, should, whole, whom]</td>\n",
       "      <td>[wide, wed, we'd, wood, weed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>hurt</td>\n",
       "      <td>hrt</td>\n",
       "      <td>1</td>\n",
       "      <td>hot</td>\n",
       "      <td>[hot, hat, hut, hart, art]</td>\n",
       "      <td>[heart, hurt, hart, hereto, heriot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>pitch</td>\n",
       "      <td>pich</td>\n",
       "      <td>1</td>\n",
       "      <td>rich</td>\n",
       "      <td>[rich, pick, pitch, pinch, ich]</td>\n",
       "      <td>[patch, pitch, pouch, peach, pooch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>journey</td>\n",
       "      <td>jerny</td>\n",
       "      <td>3</td>\n",
       "      <td>jerky</td>\n",
       "      <td>[jerky, jenny]</td>\n",
       "      <td>[journey, jenny, jerky, jerry, jersey]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>chicken</td>\n",
       "      <td>chickin</td>\n",
       "      <td>1</td>\n",
       "      <td>chicken</td>\n",
       "      <td>[chicken]</td>\n",
       "      <td>[chicken, chicane, chickens, checking, chucking]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>inning</td>\n",
       "      <td>ining</td>\n",
       "      <td>1</td>\n",
       "      <td>dining</td>\n",
       "      <td>[dining, lining, mining, pining, iting]</td>\n",
       "      <td>[annoying, owning, inning, awning, mining]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>get</td>\n",
       "      <td>git</td>\n",
       "      <td>1</td>\n",
       "      <td>git</td>\n",
       "      <td>[git]</td>\n",
       "      <td>[get, got, gate, goat, ghetto]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>purple</td>\n",
       "      <td>prepol</td>\n",
       "      <td>4</td>\n",
       "      <td>repel</td>\n",
       "      <td>[repel, propos, cresol]</td>\n",
       "      <td>[purple, propel, preppy, prep, repel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>wild</td>\n",
       "      <td>waerd</td>\n",
       "      <td>3</td>\n",
       "      <td>ward</td>\n",
       "      <td>[ward]</td>\n",
       "      <td>[word, ward, weird, wired, worried]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>became</td>\n",
       "      <td>bekame</td>\n",
       "      <td>1</td>\n",
       "      <td>became</td>\n",
       "      <td>[became]</td>\n",
       "      <td>[become, became, beam, blame, becomes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>onions</td>\n",
       "      <td>oniens</td>\n",
       "      <td>1</td>\n",
       "      <td>onions</td>\n",
       "      <td>[onions]</td>\n",
       "      <td>[announce, unions, onions, oneness, annoyance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>road</td>\n",
       "      <td>rood</td>\n",
       "      <td>1</td>\n",
       "      <td>room</td>\n",
       "      <td>[room, good, road, wood, food]</td>\n",
       "      <td>[read, red, road, radio, ride]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>bunnies</td>\n",
       "      <td>donis</td>\n",
       "      <td>4</td>\n",
       "      <td>denis</td>\n",
       "      <td>[denis]</td>\n",
       "      <td>[dance, dennis, dense, downs, diagnose]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>practice</td>\n",
       "      <td>pratis</td>\n",
       "      <td>3</td>\n",
       "      <td>parts</td>\n",
       "      <td>[parts, parties, paris, rates, praise]</td>\n",
       "      <td>[parts, parties, ports, pirates, protease]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>white</td>\n",
       "      <td>whit</td>\n",
       "      <td>1</td>\n",
       "      <td>whit</td>\n",
       "      <td>[whit]</td>\n",
       "      <td>[what, white, weight, wait, wet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>husky</td>\n",
       "      <td>husche</td>\n",
       "      <td>3</td>\n",
       "      <td>muscle</td>\n",
       "      <td>[muscle, hushed, hush, hunched]</td>\n",
       "      <td>[husk, muskie, husky, hassle, rescue]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>ever</td>\n",
       "      <td>evr</td>\n",
       "      <td>1</td>\n",
       "      <td>ever</td>\n",
       "      <td>[ever, ear, eve, er, ver]</td>\n",
       "      <td>[over, ever, oeuvre, eve, er]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>every</td>\n",
       "      <td>avery</td>\n",
       "      <td>1</td>\n",
       "      <td>very</td>\n",
       "      <td>[very, every, avert]</td>\n",
       "      <td>[every, ivory, ovary, aviary, very]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>from</td>\n",
       "      <td>fram</td>\n",
       "      <td>1</td>\n",
       "      <td>from</td>\n",
       "      <td>[from, farm, frame, dram, ram]</td>\n",
       "      <td>[from, forum, form, farm, frame]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>reaper</td>\n",
       "      <td>repe</td>\n",
       "      <td>2</td>\n",
       "      <td>rope</td>\n",
       "      <td>[rope, rep, ripe, repel, rete]</td>\n",
       "      <td>[rape, rep, wrap, rap, ripe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>pretty</td>\n",
       "      <td>prite</td>\n",
       "      <td>3</td>\n",
       "      <td>write</td>\n",
       "      <td>[write, price, pride, prime, prize]</td>\n",
       "      <td>[part, port, puerto, pirate, parrot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>ride</td>\n",
       "      <td>riad</td>\n",
       "      <td>2</td>\n",
       "      <td>road</td>\n",
       "      <td>[road, read, rid, raid]</td>\n",
       "      <td>[read, red, road, radio, ride]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>something</td>\n",
       "      <td>sum thing</td>\n",
       "      <td>2</td>\n",
       "      <td>something</td>\n",
       "      <td>[something]</td>\n",
       "      <td>[something, smoothing, somethings, summing, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>vacation</td>\n",
       "      <td>vacashin</td>\n",
       "      <td>3</td>\n",
       "      <td>vacashin</td>\n",
       "      <td>[vacashin]</td>\n",
       "      <td>[vacation, vocation, vacations, evacuation, oc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>was</td>\n",
       "      <td>wus</td>\n",
       "      <td>1</td>\n",
       "      <td>was</td>\n",
       "      <td>[was, us, pus, bus]</td>\n",
       "      <td>[was, who's, ways, whose, wise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>explosion</td>\n",
       "      <td>explosin</td>\n",
       "      <td>1</td>\n",
       "      <td>explosion</td>\n",
       "      <td>[explosion]</td>\n",
       "      <td>[explosion, explosive, explain, expulsion, exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>sugary</td>\n",
       "      <td>sugry</td>\n",
       "      <td>1</td>\n",
       "      <td>sugary</td>\n",
       "      <td>[sugary]</td>\n",
       "      <td>[sugary, surgery, slurry, surrey, scurry]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Target    Spelling  l_dist textblob_correct  \\\n",
       "487        games        gams       1             game   \n",
       "309    following     fouling       3          feeling   \n",
       "190      friends      frinds       1          friends   \n",
       "1077     through      though       1           though   \n",
       "289    chocolate    chokelet       4         chokelet   \n",
       "484         with       wheth       2            wyeth   \n",
       "1055        some         sum       2              sum   \n",
       "48        cookie     coockie       1          coockie   \n",
       "663      climbed      clamed       2          claimed   \n",
       "1247     breathe      breevu       4           breeze   \n",
       "900    traveling  travelling       1       travelling   \n",
       "893       taking     takeing       1           taking   \n",
       "478      because       becus       2          because   \n",
       "13       Johnson      Jonsun       2           Consul   \n",
       "161           of         ove       2              one   \n",
       "327      running      raning       2          ranging   \n",
       "986       dollar        dolr       2             door   \n",
       "463           me         mi        2              mid   \n",
       "954        Texas       texes       2            texas   \n",
       "336         with       whith       1             with   \n",
       "459       cousin       cosen       2           chosen   \n",
       "912         cool        coll       1             cold   \n",
       "1107         all         oll       1              all   \n",
       "1129  laboratory   labartory       2       laboratory   \n",
       "8         carrot       carit       2             cart   \n",
       "611         some         som       1               so   \n",
       "317      walking      woking       2          working   \n",
       "234         they        thay       1             that   \n",
       "632         time         tim       1              tim   \n",
       "866        first       frist       2            first   \n",
       "...          ...         ...     ...              ...   \n",
       "104     happened     hapened       1         happened   \n",
       "635   classrooms    clasrums       3         clasrums   \n",
       "1228     science      sience       1            since   \n",
       "672        would       whoud       2              who   \n",
       "1110        hurt         hrt       1              hot   \n",
       "822        pitch        pich       1             rich   \n",
       "445      journey       jerny       3            jerky   \n",
       "1219     chicken     chickin       1          chicken   \n",
       "434       inning       ining       1           dining   \n",
       "1259         get         git       1              git   \n",
       "599       purple      prepol       4            repel   \n",
       "442         wild       waerd       3             ward   \n",
       "884       became      bekame       1           became   \n",
       "81        onions      oniens       1           onions   \n",
       "1070        road        rood       1             room   \n",
       "562      bunnies       donis       4            denis   \n",
       "918     practice      pratis       3            parts   \n",
       "1164       white        whit       1             whit   \n",
       "1157       husky      husche       3           muscle   \n",
       "1300        ever         evr       1             ever   \n",
       "914        every       avery       1             very   \n",
       "837         from        fram       1             from   \n",
       "710       reaper        repe       2             rope   \n",
       "920       pretty       prite       3            write   \n",
       "467         ride        riad       2             road   \n",
       "144    something   sum thing       2        something   \n",
       "808     vacation    vacashin       3         vacashin   \n",
       "25           was         wus       1              was   \n",
       "1043   explosion    explosin       1        explosion   \n",
       "1214      sugary       sugry       1           sugary   \n",
       "\n",
       "                               textblob_suggestions  \\\n",
       "487                  [game, gas, gems, gums, games]   \n",
       "309   [feeling, forming, falling, filling, failing]   \n",
       "190                                [friends, finds]   \n",
       "1077                                       [though]   \n",
       "289                                      [chokelet]   \n",
       "484                                         [wyeth]   \n",
       "1055                                          [sum]   \n",
       "48                                        [coockie]   \n",
       "663      [claimed, blamed, flamed, clamped, calmed]   \n",
       "1247        [breeze, breed, breech, breezy, breeds]   \n",
       "900                                    [travelling]   \n",
       "893                                        [taking]   \n",
       "478            [because, begun, bells, focus, bees]   \n",
       "13                                         [Consul]   \n",
       "161                     [one, over, love, ve, move]   \n",
       "327      [ranging, raging, racing, waning, raining]   \n",
       "986                        [door, doll, dorr, dole]   \n",
       "463                        [mid, mix, mi, mio, min]   \n",
       "954             [texas, taxes, texts, teres, sexes]   \n",
       "336                      [with, which, white, whit]   \n",
       "459                                 [chosen, posen]   \n",
       "912                  [cold, call, coal, toll, roll]   \n",
       "1107                       [all, old, ll, ill, oil]   \n",
       "1129                                   [laboratory]   \n",
       "8                                     [cart, caret]   \n",
       "611                       [so, some, son, sum, sob]   \n",
       "317       [working, waking, joking, wooing, poking]   \n",
       "234                    [that, they, than, thy, hay]   \n",
       "632                                           [tim]   \n",
       "866              [first, wrist, frost, fist, grist]   \n",
       "...                                             ...   \n",
       "104                                      [happened]   \n",
       "635                                      [clasrums]   \n",
       "1228              [since, silence, science, spence]   \n",
       "672               [who, would, should, whole, whom]   \n",
       "1110                     [hot, hat, hut, hart, art]   \n",
       "822                 [rich, pick, pitch, pinch, ich]   \n",
       "445                                  [jerky, jenny]   \n",
       "1219                                      [chicken]   \n",
       "434         [dining, lining, mining, pining, iting]   \n",
       "1259                                          [git]   \n",
       "599                         [repel, propos, cresol]   \n",
       "442                                          [ward]   \n",
       "884                                        [became]   \n",
       "81                                         [onions]   \n",
       "1070                 [room, good, road, wood, food]   \n",
       "562                                         [denis]   \n",
       "918          [parts, parties, paris, rates, praise]   \n",
       "1164                                         [whit]   \n",
       "1157                [muscle, hushed, hush, hunched]   \n",
       "1300                      [ever, ear, eve, er, ver]   \n",
       "914                            [very, every, avert]   \n",
       "837                  [from, farm, frame, dram, ram]   \n",
       "710                  [rope, rep, ripe, repel, rete]   \n",
       "920             [write, price, pride, prime, prize]   \n",
       "467                         [road, read, rid, raid]   \n",
       "144                                     [something]   \n",
       "808                                      [vacashin]   \n",
       "25                              [was, us, pus, bus]   \n",
       "1043                                    [explosion]   \n",
       "1214                                       [sugary]   \n",
       "\n",
       "                                  metaphone_suggestions  \n",
       "487                    [games, gems, gyms, gums, grams]  \n",
       "309       [following, feeling, flying, filing, falling]  \n",
       "190           [friends, fronds, grinds, finds, forints]  \n",
       "1077          [though, thigh, through, tough, thorough]  \n",
       "289       [chocolate, collet, chalet, booklet, chaplet]  \n",
       "484               [with, whet, whether, sheath, wreath]  \n",
       "1055                      [some, same, seem, zoom, sam]  \n",
       "48                     [cock, cook, cake, kick, cookie]  \n",
       "663          [claimed, calmed, clamped, flamed, clawed]  \n",
       "1247              [brave, bravo, brava, breeze, breech]  \n",
       "900   [traveling, travelling, revealing, trailing, t...  \n",
       "893       [taking, ticking, tacking, tucking, tackling]  \n",
       "478               [books, because, bikes, bucks, backs]  \n",
       "13     [Johnson, Consign, Monsoon, Johnsons, Consignee]  \n",
       "161                       [i've, eve, hove, oven, over]  \n",
       "327     [running, raining, renewing, ruining, reigning]  \n",
       "986               [dollar, dealer, delaware, doll, dol]  \n",
       "463                                [me, ma, mm, mi, mo]  \n",
       "954                  [texas, taxes, taxis, tees, sexes]  \n",
       "336                 [with, white, whit, which, whither]  \n",
       "459           [casino, cuisine, cousin, cosine, casein]  \n",
       "912                      [call, cool, kill, coal, cole]  \n",
       "1107                        [all, i'll, al, oil, allow]  \n",
       "1129  [laboratory, liberators, laboratories, liberat...  \n",
       "8                  [cart, create, court, carat, karate]  \n",
       "611                       [some, same, seem, zoom, sam]  \n",
       "317         [waking, whacking, working, joking, wooing]  \n",
       "234                       [they, chay, hay, than, that]  \n",
       "632                        [time, team, tom, tim, tome]  \n",
       "866          [first, forest, frost, foresight, fairest]  \n",
       "...                                                 ...  \n",
       "104     [happened, ripened, opened, reopened, deepened]  \n",
       "635        [classrooms, classroom, closures, kilograms]  \n",
       "1228             [since, science, sense, signs, scenes]  \n",
       "672                       [wide, wed, we'd, wood, weed]  \n",
       "1110                [heart, hurt, hart, hereto, heriot]  \n",
       "822                 [patch, pitch, pouch, peach, pooch]  \n",
       "445              [journey, jenny, jerky, jerry, jersey]  \n",
       "1219   [chicken, chicane, chickens, checking, chucking]  \n",
       "434          [annoying, owning, inning, awning, mining]  \n",
       "1259                     [get, got, gate, goat, ghetto]  \n",
       "599               [purple, propel, preppy, prep, repel]  \n",
       "442                 [word, ward, weird, wired, worried]  \n",
       "884              [become, became, beam, blame, becomes]  \n",
       "81       [announce, unions, onions, oneness, annoyance]  \n",
       "1070                     [read, red, road, radio, ride]  \n",
       "562             [dance, dennis, dense, downs, diagnose]  \n",
       "918          [parts, parties, ports, pirates, protease]  \n",
       "1164                   [what, white, weight, wait, wet]  \n",
       "1157              [husk, muskie, husky, hassle, rescue]  \n",
       "1300                      [over, ever, oeuvre, eve, er]  \n",
       "914                 [every, ivory, ovary, aviary, very]  \n",
       "837                    [from, forum, form, farm, frame]  \n",
       "710                        [rape, rep, wrap, rap, ripe]  \n",
       "920                [part, port, puerto, pirate, parrot]  \n",
       "467                      [read, red, road, radio, ride]  \n",
       "144   [something, smoothing, somethings, summing, su...  \n",
       "808   [vacation, vocation, vacations, evacuation, oc...  \n",
       "25                      [was, who's, ways, whose, wise]  \n",
       "1043  [explosion, explosive, explain, expulsion, exp...  \n",
       "1214          [sugary, surgery, slurry, surrey, scurry]  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev[50:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7757894736842105"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = []\n",
    "problem_words = []\n",
    "for target, spelling, suggestions in zip(dev[\"Target\"], dev[\"Spelling\"], dev[\"metaphone_suggestions\"]):\n",
    "    if target in suggestions or target.lower() in suggestions or target[0].upper() + target[1:].lower() in suggestions:\n",
    "        correct.append(True)\n",
    "    else:\n",
    "        problem_words.append((target, spelling, mphone(target),mphone(spelling), suggestions))\n",
    "        correct.append(False)\n",
    "        \n",
    "sum_list(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('pink', 'peik', 'PNK', 'PK', ['pc', 'pack', 'pick', 'peak', 'pac']),\n",
       " ('gills', 'gils', 'GLS', 'GLS', ['glass', 'goals', 'gals', 'gloss', 'glaze']),\n",
       " ('go on', 'gowen', 'GN', 'GN', ['gone', 'gene', 'gain', 'gun', 'guinea']),\n",
       " ('pictures',\n",
       "  'pitchers',\n",
       "  'PKTRS',\n",
       "  'P1RS',\n",
       "  ['pitchers', 'poachers', 'pitcher', 'pitches', 'watchers']),\n",
       " ('simple',\n",
       "  'sipl',\n",
       "  'SMPL',\n",
       "  'SPL',\n",
       "  ['spell', 'spill', 'spool', 'spoil', 'supple']),\n",
       " ('princess',\n",
       "  'priins',\n",
       "  'PRNSS',\n",
       "  'PRNS',\n",
       "  ['prince', 'prawns', 'prunes', 'prunus', 'sprains']),\n",
       " ('climbed',\n",
       "  'clamed',\n",
       "  'KLMBD',\n",
       "  'KLMD',\n",
       "  ['claimed', 'calmed', 'clamped', 'flamed', 'clawed']),\n",
       " ('breathe',\n",
       "  'breevu',\n",
       "  'BR0',\n",
       "  'BRV',\n",
       "  ['brave', 'bravo', 'brava', 'breeze', 'breech']),\n",
       " ('of', 'ove', 'AF', 'AV', [\"i've\", 'eve', 'hove', 'oven', 'over']),\n",
       " ('carrot',\n",
       "  'carit',\n",
       "  'KRT',\n",
       "  'KRT',\n",
       "  ['cart', 'create', 'court', 'carat', 'karate']),\n",
       " ('walking',\n",
       "  'woking',\n",
       "  'WLKNG',\n",
       "  'WKNG',\n",
       "  ['waking', 'whacking', 'working', 'joking', 'wooing']),\n",
       " ('walked',\n",
       "  'wokt',\n",
       "  'WLKD',\n",
       "  'WKT',\n",
       "  ['wicket', 'woke', 'wort', \"won't\", 'woken']),\n",
       " ('drink',\n",
       "  'dring',\n",
       "  'DRNK',\n",
       "  'DRNG',\n",
       "  ['during', 'drawing', 'drainage', 'drying', 'daring']),\n",
       " ('meaty', 'mete', 'MTA', 'MT', ['might', 'meet', 'met', 'matt', 'meat']),\n",
       " (\"it's\", 'es', 'ATS', 'AS', ['is', 'as', 'us', 'use', 'usa']),\n",
       " ('where', 'wr', 'WR', 'R', ['re', 'row', 'raw', 'rio', 'rue']),\n",
       " ('fell', 'fel', 'FL', 'FL', ['full', 'file', 'feel', 'follow', 'fall']),\n",
       " ('they', 'day', '0A', 'DA', ['day', 'dewy', 'days', 'dray', 'nay']),\n",
       " ('world', 'war', 'WRLD', 'WR', ['were', 'where', 'war', \"we're\", 'wire']),\n",
       " ('beginning',\n",
       "  'being',\n",
       "  'BGNNG',\n",
       "  'BNG',\n",
       "  ['being', 'buying', 'bang', 'bingo', 'boing']),\n",
       " ('ran', 'wand', 'RN', 'WND', ['window', 'wind', 'wound', 'wand', 'weaned']),\n",
       " ('mule', 'muole', 'ML', 'ML', ['mail', 'male', 'mile', 'mall', 'mill']),\n",
       " ('would', 'whoud', 'WLD', 'WD', ['wide', 'wed', \"we'd\", 'wood', 'weed']),\n",
       " ('wild',\n",
       "  'waerd',\n",
       "  'WLD',\n",
       "  'WRD',\n",
       "  ['word', 'ward', 'weird', 'wired', 'worried']),\n",
       " ('bunnies',\n",
       "  'donis',\n",
       "  'BNS',\n",
       "  'DNS',\n",
       "  ['dance', 'dennis', 'dense', 'downs', 'diagnose']),\n",
       " ('practice',\n",
       "  'pratis',\n",
       "  'PRKTS',\n",
       "  'PRTS',\n",
       "  ['parts', 'parties', 'ports', 'pirates', 'protease']),\n",
       " ('reaper', 'repe', 'RPR', 'RP', ['rape', 'rep', 'wrap', 'rap', 'ripe']),\n",
       " ('pretty',\n",
       "  'prite',\n",
       "  'PRTA',\n",
       "  'PRT',\n",
       "  ['part', 'port', 'puerto', 'pirate', 'parrot']),\n",
       " ('ground',\n",
       "  'groud',\n",
       "  'GRND',\n",
       "  'GRD',\n",
       "  ['grade', 'guard', 'grid', 'geared', 'greed']),\n",
       " ('would', 'wuod', 'WLD', 'WD', ['wide', 'wed', \"we'd\", 'wood', 'weed']),\n",
       " ('next', 'neks', 'NXT', 'NKS', ['knocks', 'necks', 'nicks', 'nooks', 'nets']),\n",
       " ('me', 'my', 'M', 'MA', ['my', 'may', 'amy', 'myth', 'emmy']),\n",
       " ('fries',\n",
       "  'frice',\n",
       "  'FRS',\n",
       "  'FRS',\n",
       "  ['force', 'phrase', 'fires', 'fears', 'freeze']),\n",
       " ('sled',\n",
       "  'sleded',\n",
       "  'SLD',\n",
       "  'SLDD',\n",
       "  ['seeded', 'pleaded', 'speeded', 'sleeved', 'slide']),\n",
       " ('through', 'thow', '0RGH', '0', ['the', 'thou', 'thaw', 'throw', 'chow']),\n",
       " ('dumb', 'dume', 'DM', 'DM', ['demo', 'dam', 'dom', 'doom', 'dame']),\n",
       " ('tickets',\n",
       "  'tietts',\n",
       "  'TKTS',\n",
       "  'TTS',\n",
       "  ['tattoos', 'tights', 'titties', 'tots', 'touts']),\n",
       " ('easy', 'ese', 'ASA', 'AS', ['is', 'as', 'us', 'use', 'usa']),\n",
       " ('glove', 'gloff', 'GLV', 'GLF', ['golf', 'gulf', 'loaf', 'luff', 'bluff']),\n",
       " ('ran',\n",
       "  'rand',\n",
       "  'RN',\n",
       "  'RND',\n",
       "  ['round', 'rand', 'renewed', 'ruined', 'rewind']),\n",
       " ('presents',\n",
       "  'pisits',\n",
       "  'PRSNTS',\n",
       "  'PSTS',\n",
       "  ['posts', 'pests', 'pastas', 'pastes', 'posits']),\n",
       " ('jungle',\n",
       "  'gugl',\n",
       "  'JNGL',\n",
       "  'GGL',\n",
       "  ['google', 'goggle', 'giggle', 'gaggle', 'googol']),\n",
       " ('ran',\n",
       "  'rand',\n",
       "  'RN',\n",
       "  'RND',\n",
       "  ['round', 'rand', 'renewed', 'ruined', 'rewind']),\n",
       " ('talking',\n",
       "  'tokeg',\n",
       "  'TLKNG',\n",
       "  'TKG',\n",
       "  ['toke', 'token', 'takes', 'tykes', 'take']),\n",
       " ('can', 'cin', 'KN', 'SN', ['sign', 'san', 'sun', 'seen', 'soon']),\n",
       " ('a lot',\n",
       "  'a lout',\n",
       "  'ALT',\n",
       "  'ALT',\n",
       "  ['elite', 'alt', 'alto', 'eyelet', 'allot']),\n",
       " ('Monday',\n",
       "  'modas',\n",
       "  'MNDA',\n",
       "  'MDS',\n",
       "  ['modes', 'mods', 'meadows', 'moods', 'maids']),\n",
       " ('world',\n",
       "  'wolde',\n",
       "  'WRLD',\n",
       "  'WLD',\n",
       "  ['would', 'wild', 'weld', 'wheeled', 'walled']),\n",
       " ('success',\n",
       "  'sucsses',\n",
       "  'SSS',\n",
       "  'SKSS',\n",
       "  ['successes', 'suitcases', 'caucuses', 'focusses', 'supposes']),\n",
       " ('stuffed',\n",
       "  'stof',\n",
       "  'STFD',\n",
       "  'STF',\n",
       "  ['staff', 'stuff', 'stiff', 'stop', 'stow']),\n",
       " ('soars',\n",
       "  'sors',\n",
       "  'SRS',\n",
       "  'SRS',\n",
       "  ['source', 'series', 'serious', 'zeros', 'sores']),\n",
       " ('eat', 'eta', 'AT', 'AT', ['it', 'at', 'out', 'et', 'auto']),\n",
       " ('fell', 'fel', 'FL', 'FL', ['full', 'file', 'feel', 'follow', 'fall']),\n",
       " ('world',\n",
       "  'wolde',\n",
       "  'WRLD',\n",
       "  'WLD',\n",
       "  ['would', 'wild', 'weld', 'wheeled', 'walled']),\n",
       " ('tickets',\n",
       "  'ticettes',\n",
       "  'TKTS',\n",
       "  'TSTS',\n",
       "  ['tests', 'tastes', 'toasts', 'tsetse', 'niceties']),\n",
       " ('beach', 'btit', 'B1', 'BTT', ['brit', 'bit', 'bait', 'built', 'baits']),\n",
       " ('fright',\n",
       "  'frait',\n",
       "  'FRT',\n",
       "  'FRT',\n",
       "  ['fort', 'fruit', 'freight', 'ferret', 'fart']),\n",
       " ('friends',\n",
       "  'frend',\n",
       "  'FRNDS',\n",
       "  'FRND',\n",
       "  ['friend', 'frowned', 'trend', 'fred', 'freed']),\n",
       " ('of', 'uv', 'AF', 'AV', [\"i've\", 'eve', 'luv', 'tv', 'ut']),\n",
       " ('they', 'thae', '0A', '0', ['the', 'thou', 'thaw', 'thane', 'that']),\n",
       " ('would', 'wode', 'WLD', 'WD', ['wide', 'wed', \"we'd\", 'wood', 'weed']),\n",
       " ('beach',\n",
       "  'deach',\n",
       "  'B1',\n",
       "  'D1',\n",
       "  ['dutch', 'ditch', 'douche', 'detach', 'teach']),\n",
       " ('kitty', 'kide', 'KTA', 'KD', ['code', 'cd', 'kid', 'cod', 'coed']),\n",
       " ('could', 'codd', 'KLD', 'KD', ['code', 'cd', 'kid', 'cod', 'coed']),\n",
       " ('becasue',\n",
       "  'bicos',\n",
       "  'BKS',\n",
       "  'BKS',\n",
       "  ['books', 'because', 'bikes', 'bucks', 'backs']),\n",
       " ('soda', 'sode', 'SD', 'SD', ['said', 'side', 'seed', 'saudi', 'sad']),\n",
       " ('together',\n",
       "  'toger',\n",
       "  'TG0R',\n",
       "  'TGR',\n",
       "  ['tiger', 'tagger', 'roger', 'toner', 'tower']),\n",
       " ('ice-cream',\n",
       "  'ice-crem',\n",
       "  'ASKRM',\n",
       "  'ASKRM',\n",
       "  ['isoform', 'scream', 'scrum', 'scrim', 'sacrum']),\n",
       " ('exploded', 'xspladed', 'AXPLDD', 'SSPLDD', ['suspended']),\n",
       " ('family',\n",
       "  'famelli',\n",
       "  'FMLA',\n",
       "  'FML',\n",
       "  ['female', 'camellia', 'fall', 'fell', 'fella']),\n",
       " ('go', 'og', 'G', 'AG', ['age', 'ago', 'ag', 'egg', 'ego']),\n",
       " ('scooped',\n",
       "  'scoot',\n",
       "  'SKPD',\n",
       "  'SKT',\n",
       "  ['scott', 'socket', 'scout', 'skate', 'sect']),\n",
       " ('learned',\n",
       "  'leared',\n",
       "  'LRND',\n",
       "  'LRD',\n",
       "  ['lord', 'lowered', 'layered', 'laird', 'lured']),\n",
       " ('teddy',\n",
       "  'tedyear',\n",
       "  'TDA',\n",
       "  'TDR',\n",
       "  ['teaser', 'teeter', 'redder', 'cedar', 'tenner']),\n",
       " ('ground',\n",
       "  'groud',\n",
       "  'GRND',\n",
       "  'GRD',\n",
       "  ['grade', 'guard', 'grid', 'geared', 'greed']),\n",
       " ('caught',\n",
       "  'catched',\n",
       "  'KT',\n",
       "  'K1D',\n",
       "  ['cached', 'coached', 'couched', 'watched', 'matched']),\n",
       " ('licorice', 'likrorish', 'LKRS', 'LKRR2', []),\n",
       " ('bunny', 'bne', 'BNA', 'BN', ['been', 'bin', 'ben', 'bone', 'ban']),\n",
       " ('teacher',\n",
       "  'therecer',\n",
       "  'T1R',\n",
       "  '0RSR',\n",
       "  ['therefor', 'therefore', 'thrower', 'mercer', 'tracer']),\n",
       " ('sled',\n",
       "  'slead',\n",
       "  'SLD',\n",
       "  'SLD',\n",
       "  ['sold', 'solid', 'slide', 'sealed', 'salad']),\n",
       " ('gasped',\n",
       "  'gast',\n",
       "  'GSPD',\n",
       "  'GST',\n",
       "  ['guest', 'ghost', 'gust', 'gist', 'gusset']),\n",
       " ('going to (gonna)',\n",
       "  'gona',\n",
       "  'GNGTGN',\n",
       "  'GN',\n",
       "  ['gone', 'gene', 'gain', 'gun', 'guinea']),\n",
       " ('keep', 'cip', 'KP', 'SP', ['zip', 'spa', 'soap', 'soup', 'sap']),\n",
       " ('kept', 'kep', 'KPT', 'KP', ['keep', 'cup', 'cape', 'cap', 'cop']),\n",
       " ('moose', 'mose', 'MS', 'MS', ['mass', 'miss', 'mouse', 'mice', 'mess']),\n",
       " ('listen',\n",
       "  'lisan',\n",
       "  'LSTN',\n",
       "  'LSN',\n",
       "  ['lesson', 'liaison', 'lessen', 'loosen', 'lasagna']),\n",
       " ('kind', 'cian', 'KND', '2N', ['shown', 'shine', 'shawn', 'shin', 'sheen']),\n",
       " ('ohter', 'othe', 'AHTR', 'A0', ['oath', 'other', 'the', 'loathe', 'soothe']),\n",
       " ('scooter',\n",
       "  'suter',\n",
       "  'SKTR',\n",
       "  'STR',\n",
       "  ['store', 'star', 'stereo', 'stir', 'straw']),\n",
       " ('went', 'wen', 'WNT', 'WN', ['when', 'win', 'wine', 'won', 'wayne']),\n",
       " ('chewed', 'cewed', '1D', 'SD', ['said', 'side', 'seed', 'saudi', 'sad']),\n",
       " ('through', 'thow', '0RGH', '0', ['the', 'thou', 'thaw', 'throw', 'chow']),\n",
       " ('court',\n",
       "  'korts',\n",
       "  'KRT',\n",
       "  'KRTS',\n",
       "  ['courts', 'creates', 'carts', 'carrots', 'courteous']),\n",
       " ('sled',\n",
       "  'sleed',\n",
       "  'SLD',\n",
       "  'SLD',\n",
       "  ['sold', 'solid', 'slide', 'sealed', 'salad']),\n",
       " ('can', 'cen', 'KN', 'SN', ['sign', 'san', 'sun', 'seen', 'soon']),\n",
       " ('that', 'tat', '0T', 'TT', ['tight', 'taught', 'toyota', 'tattoo', 'tot']),\n",
       " ('ammo', 'amoe', 'AM', 'AM', ['am', \"i'm\", 'em', 'aim', 'um']),\n",
       " ('broke', 'boke', 'BRK', 'BK', ['back', 'book', 'bbc', 'bike', 'buck']),\n",
       " ('strike',\n",
       "  'stick',\n",
       "  'STRK',\n",
       "  'STK',\n",
       "  ['stock', 'stick', 'stack', 'stuck', 'stake']),\n",
       " ('dream', 'grem', 'DRM', 'GRM', ['gram', 'grim', 'groom', 'germ', 'grime']),\n",
       " ('court',\n",
       "  'korts',\n",
       "  'KRT',\n",
       "  'KRTS',\n",
       "  ['courts', 'creates', 'carts', 'carrots', 'courteous']),\n",
       " ('brought',\n",
       "  'drot',\n",
       "  'BRT',\n",
       "  'DRT',\n",
       "  ['dirt', 'drought', 'dart', 'droit', 'draught']),\n",
       " ('fish', 'fis', 'F2', 'FS', ['face', 'fees', 'phase', 'fuse', 'fuss']),\n",
       " ('foul',\n",
       "  'faerl',\n",
       "  'FL',\n",
       "  'FRL',\n",
       "  ['farewell', 'feral', 'frail', 'ferrule', 'frill']),\n",
       " ('used',\n",
       "  'yowst',\n",
       "  'ASD',\n",
       "  'YST',\n",
       "  ['yeast', 'lowest', 'joist', 'joust', 'dost']),\n",
       " ('already',\n",
       "  'oridi',\n",
       "  'ALRDA',\n",
       "  'ARD',\n",
       "  ['aired', 'arid', 'erred', 'erode', 'eared']),\n",
       " ('uses', 'yus', 'ASS', 'YS', ['yes', 'yum', 'yuk', 'pus', 'jus']),\n",
       " ('freaked',\n",
       "  'freat',\n",
       "  'FRKD',\n",
       "  'FRT',\n",
       "  ['fort', 'fruit', 'freight', 'ferret', 'fart']),\n",
       " ('play', 'pla', 'PLA', 'PL', ['paul', 'pool', 'poll', 'pull', 'pill']),\n",
       " ('going to', 'goeto', 'GNGT', 'GT', ['get', 'got', 'gate', 'goat', 'ghetto']),\n",
       " ('play', 'ple', 'PLA', 'PL', ['paul', 'pool', 'poll', 'pull', 'pill']),\n",
       " ('king',\n",
       "  'cing',\n",
       "  'KNG',\n",
       "  'SNG',\n",
       "  ['song', 'saying', 'seeing', 'sing', 'sewing']),\n",
       " ('could', 'cud', 'KLD', 'KD', ['code', 'cd', 'kid', 'cod', 'coed']),\n",
       " ('conquer',\n",
       "  'concer',\n",
       "  'KNQR',\n",
       "  'KNSR',\n",
       "  ['cancer', 'connoisseur', 'concert', 'concern', 'conner']),\n",
       " ('float',\n",
       "  'flowt',\n",
       "  'FLT',\n",
       "  'FLT',\n",
       "  ['flat', 'flight', 'felt', 'fault', 'fleet']),\n",
       " ('a lot', 'allot', 'ALT', 'ALT', ['elite', 'alt', 'alto', 'eyelet', 'allot']),\n",
       " ('baby', 'bae', 'BBA', 'B', ['be', 'bio', 'ba', 'bi', 'bow']),\n",
       " ('charged',\n",
       "  'chard',\n",
       "  '1RGD',\n",
       "  '1RD',\n",
       "  ['chord', 'chaired', 'cheered', 'chard', 'charade']),\n",
       " ('would', 'wode', 'WLD', 'WD', ['wide', 'wed', \"we'd\", 'wood', 'weed']),\n",
       " ('climbed',\n",
       "  'clamed',\n",
       "  'KLMBD',\n",
       "  'KLMD',\n",
       "  ['claimed', 'calmed', 'clamped', 'flamed', 'clawed']),\n",
       " ('peanut butter', 'peanot doter', 'PNTBTR', 'PNTDTR', []),\n",
       " ('candy',\n",
       "  'cand',\n",
       "  'KNDA',\n",
       "  'KND',\n",
       "  ['canada', 'kind', 'canned', 'coined', 'kendo']),\n",
       " ('bell', 'bel', 'BL', 'BL', ['below', 'blue', 'bill', 'ball', 'blow']),\n",
       " ('by', 'be', 'BA', 'B', ['be', 'bio', 'ba', 'bi', 'bow']),\n",
       " ('chick', 'kik', '1K', 'KK', ['cock', 'cook', 'cake', 'kick', 'cookie']),\n",
       " ('walk', 'wok', 'WLK', 'WK', ['week', 'wake', 'weak', 'woke', 'wick']),\n",
       " ('squish',\n",
       "  'skwish',\n",
       "  'SQ2',\n",
       "  'SKW2',\n",
       "  ['swish', 'swash', 'scottish', 'backwash', 'scotia']),\n",
       " ('kick', 'kice', 'KK', 'KS', ['case', 'cause', 'keys', 'kiss', 'cos']),\n",
       " ('shower', 'sower', '2R', 'SR', ['sure', 'zero', 'sarah', 'sir', 'sierra']),\n",
       " ('could', 'cud', 'KLD', 'KD', ['code', 'cd', 'kid', 'cod', 'coed']),\n",
       " ('temperature',\n",
       "  'tempechers',\n",
       "  'TMPR1R',\n",
       "  'TMP1RS',\n",
       "  ['tempers', 'temptress', 'templars']),\n",
       " ('bake', 'beick', 'BK', 'BK', ['back', 'book', 'bbc', 'bike', 'buck']),\n",
       " ('walked',\n",
       "  'wokt',\n",
       "  'WLKD',\n",
       "  'WKT',\n",
       "  ['wicket', 'woke', 'wort', \"won't\", 'woken']),\n",
       " ('Ivy', 'ive', 'AVA', 'AV', [\"i've\", 'eve', 'hive', 'jive', 'vive']),\n",
       " ('sneaked',\n",
       "  'snekt',\n",
       "  'SNKD',\n",
       "  'SNKT',\n",
       "  ['sneaky', 'sneaks', 'snort', 'snake', 'sneak']),\n",
       " ('going to', 'gunn', 'GNGT', 'GN', ['gone', 'gene', 'gain', 'gun', 'guinea']),\n",
       " ('would', 'woud', 'WLD', 'WD', ['wide', 'wed', \"we'd\", 'wood', 'weed']),\n",
       " ('friends',\n",
       "  'frins',\n",
       "  'FRNDS',\n",
       "  'FRNS',\n",
       "  ['france', 'fairness', 'furnace', 'ferns', 'frowns']),\n",
       " ('would', 'wod', 'WLD', 'WD', ['wide', 'wed', \"we'd\", 'wood', 'weed']),\n",
       " ('rollercoaster', 'rolrcostr', 'RLRKSTR', 'RLRKSTR', []),\n",
       " ('worms', 'wrms', 'WRMS', 'RMS', ['rooms', 'roms', 'rams', 'rims', 'reams']),\n",
       " ('other',\n",
       "  'oder',\n",
       "  'A0R',\n",
       "  'ADR',\n",
       "  ['adore', 'adder', 'odour', 'udder', 'eider']),\n",
       " ('once', 'wons', 'ANS', 'WNS', ['wins', 'wines', 'whence', 'wince', 'wans']),\n",
       " (\"didn't\",\n",
       "  \"din't\",\n",
       "  'DDNT',\n",
       "  'DNT',\n",
       "  [\"don't\", 'donate', 'denote', 'dent', 'doughnut']),\n",
       " ('peanut butter', 'punat butter', 'PNTBTR', 'PNTBTR', []),\n",
       " ('inside',\n",
       "  'insaen',\n",
       "  'ANSD',\n",
       "  'ANSN',\n",
       "  ['insane', 'unseen', 'insignia', 'unison', 'ensign']),\n",
       " ('pink', 'peik', 'PNK', 'PK', ['pc', 'pack', 'pick', 'peak', 'pac']),\n",
       " ('tie', 'tiy', 'T', 'TA', ['toy', 'tiny', 'tidy', 'tip', 'tis']),\n",
       " ('day', 'da', 'DA', 'D', ['do', 'de', 'due', 'die', 'doe']),\n",
       " ('could', 'cood', 'KLD', 'KD', ['code', 'cd', 'kid', 'cod', 'coed']),\n",
       " ('brother',\n",
       "  'brater',\n",
       "  'BR0R',\n",
       "  'BRTR',\n",
       "  ['brighter', 'barter', 'rater', 'grater', 'braver']),\n",
       " ('talking',\n",
       "  'tokes',\n",
       "  'TLKNG',\n",
       "  'TKS',\n",
       "  ['takes', 'ticks', 'tics', 'tacos', 'tacks']),\n",
       " ('one', 'won', 'AN', 'WN', ['when', 'win', 'wine', 'won', 'wayne']),\n",
       " ('squeaky',\n",
       "  'sqeke',\n",
       "  'SQKA',\n",
       "  'SQK',\n",
       "  ['squeak', 'squawk', 'seek', 'sake', 'spoke']),\n",
       " ('tasts',\n",
       "  'tastes',\n",
       "  'TSTS',\n",
       "  'TSTS',\n",
       "  ['tests', 'tastes', 'toasts', 'tsetse', 'tasted']),\n",
       " ('strike',\n",
       "  'stick',\n",
       "  'STRK',\n",
       "  'STK',\n",
       "  ['stock', 'stick', 'stack', 'stuck', 'stake']),\n",
       " ('hungry',\n",
       "  'hangre',\n",
       "  'HNGRA',\n",
       "  'HNGR',\n",
       "  ['hunger', 'hanger', 'hangar', 'hangers', 'hangars']),\n",
       " ('strike',\n",
       "  'stike',\n",
       "  'STRK',\n",
       "  'STK',\n",
       "  ['stock', 'stick', 'stack', 'stuck', 'stake']),\n",
       " ('recess', 'recce', 'RSS', 'RS', ['race', 'rose', 'rise', 'rice', 'raise']),\n",
       " ('fight', 'fite', 'FT', 'FT', ['photo', 'feet', 'fat', 'fit', 'foot']),\n",
       " ('catch', 'cech', 'K1', 'S1', ['such', 'czech', 'tech', 'vetch', 'cinch']),\n",
       " ('dancing',\n",
       "  'dasen',\n",
       "  'DNSNG',\n",
       "  'DSN',\n",
       "  ['design', 'dozen', 'casein', 'dose', 'daze']),\n",
       " ('friends',\n",
       "  'frins',\n",
       "  'FRNDS',\n",
       "  'FRNS',\n",
       "  ['france', 'fairness', 'furnace', 'ferns', 'frowns']),\n",
       " ('beetlejuice',\n",
       "  'beposios',\n",
       "  'BTLJS',\n",
       "  'BP2S',\n",
       "  ['biopsies', 'bypasses', 'bypass', 'patios', 'spacious']),\n",
       " ('circus',\n",
       "  'cerces',\n",
       "  'SRKS',\n",
       "  'SRSS',\n",
       "  ['sources', 'ceres', 'mercies', 'serves', 'forces']),\n",
       " ('whole', 'hole', 'WL', 'HL', [\"he'll\", 'hill', 'hall', 'hello', 'hole']),\n",
       " ('train',\n",
       "  'chran',\n",
       "  'TRN',\n",
       "  '1RN',\n",
       "  ['churn', 'choral', 'chairman', 'loran', 'ran']),\n",
       " ('fought', 'fote', 'FT', 'FT', ['photo', 'feet', 'fat', 'fit', 'foot']),\n",
       " ('girlfriend',\n",
       "  'gofrend',\n",
       "  'GRLFRND',\n",
       "  'GFRND',\n",
       "  ['boyfriend', 'befriend', 'grand', 'grind', 'friend']),\n",
       " ('first', 'fist', 'FRST', 'FST', ['fast', 'fist', 'fest', 'feast', 'fiesta']),\n",
       " ('looked', 'loot', 'LKD', 'LT', ['let', 'light', 'lot', 'late', 'layout']),\n",
       " ('tometo',\n",
       "  'tomato',\n",
       "  'TMT',\n",
       "  'TMT',\n",
       "  ['tomato', 'teammate', 'tomatoes', 'tomcat', 'automate']),\n",
       " ('flute', 'flut', 'FLT', 'FLT', ['flat', 'flight', 'felt', 'fault', 'fleet']),\n",
       " ('wild',\n",
       "  'waerled',\n",
       "  'WLD',\n",
       "  'WRLD',\n",
       "  ['world', 'whirled', 'wheeled', 'walled', 'wailed']),\n",
       " ('wheat', 'weat', 'WT', 'WT', ['what', 'white', 'weight', 'wait', 'wet']),\n",
       " ('ready', 'redea', 'RDA', 'RD', ['read', 'red', 'road', 'radio', 'ride']),\n",
       " ('want', 'wot', 'WNT', 'WT', ['what', 'white', 'weight', 'wait', 'wet']),\n",
       " ('is', 'si', 'AS', 'S', ['see', 'so', 'sea', 'saw', 'si']),\n",
       " ('self', 'sefe', 'SLF', 'SF', ['safe', 'sofa', 'see', 'suede', 'sewed']),\n",
       " ('could have',\n",
       "  'cuf av',\n",
       "  'KLDHV',\n",
       "  'KFV',\n",
       "  ['cuffs', 'cuffed', 'cuff', 'cassava', 'cafes']),\n",
       " ('chicken',\n",
       "  'chincin',\n",
       "  '1KN',\n",
       "  '1NSN',\n",
       "  ['chinese', 'chance', 'chins', 'chinos', 'chinas']),\n",
       " ('swim', 'swin', 'SWM', 'SWN', ['swan', 'swine', 'swain', 'swoon', 'swing']),\n",
       " ('friends',\n",
       "  'frenz',\n",
       "  'FRNDS',\n",
       "  'FRNS',\n",
       "  ['france', 'fairness', 'furnace', 'ferns', 'frowns']),\n",
       " ('chocolate',\n",
       "  'cockotate',\n",
       "  '1KLT',\n",
       "  'KKTT',\n",
       "  ['cocktail', 'lactate', 'cockpit', 'coconut', 'dictate']),\n",
       " ('died', 'dit', 'DD', 'DT', ['date', 'data', 'diet', 'dot', 'dit']),\n",
       " ('brother',\n",
       "  'brothe',\n",
       "  'BR0R',\n",
       "  'BR0',\n",
       "  ['birth', 'breath', 'breathe', 'broth', 'bertha']),\n",
       " ('werewolf', 'welf wof', 'WRLF', 'WLFWF', []),\n",
       " ('crowd',\n",
       "  'crard',\n",
       "  'KRD',\n",
       "  'KRRD',\n",
       "  ['card', 'canard', 'crazed', 'coward', 'craved']),\n",
       " ('fight', 'fite', 'FT', 'FT', ['photo', 'feet', 'fat', 'fit', 'foot']),\n",
       " ('foul',\n",
       "  'faerl',\n",
       "  'FL',\n",
       "  'FRL',\n",
       "  ['farewell', 'feral', 'frail', 'ferrule', 'frill']),\n",
       " ('fast', 'fas', 'FST', 'FS', ['face', 'fees', 'phase', 'fuse', 'fuss']),\n",
       " ('strike',\n",
       "  'stick',\n",
       "  'STRK',\n",
       "  'STK',\n",
       "  ['stock', 'stick', 'stack', 'stuck', 'stake']),\n",
       " ('looked',\n",
       "  'looket',\n",
       "  'LKD',\n",
       "  'LKT',\n",
       "  ['locate', 'lookout', 'lockout', 'locket', 'looker']),\n",
       " ('fair', 'fer', 'FR', 'FR', ['for', 'free', 'four', 'far', 'fire']),\n",
       " ('introduced', 'inchrodoost', 'ANTRDSD', 'AN1RDST', []),\n",
       " ('world',\n",
       "  'wolde',\n",
       "  'WRLD',\n",
       "  'WLD',\n",
       "  ['would', 'wild', 'weld', 'wheeled', 'walled']),\n",
       " ('ground',\n",
       "  'groud',\n",
       "  'GRND',\n",
       "  'GRD',\n",
       "  ['grade', 'guard', 'grid', 'geared', 'greed']),\n",
       " ('fought', 'fot', 'FT', 'FT', ['photo', 'feet', 'fat', 'fit', 'foot']),\n",
       " ('Baton Rouge',\n",
       "  'bateroosh',\n",
       "  'BTNRG',\n",
       "  'BTR2',\n",
       "  ['batteries', 'boaters', 'batters', 'beaters', 'battery']),\n",
       " ('could', 'coud', 'KLD', 'KD', ['code', 'cd', 'kid', 'cod', 'coed']),\n",
       " ('save her',\n",
       "  'safr',\n",
       "  'SVHR',\n",
       "  'SFR',\n",
       "  ['safari', 'suffer', 'sapphire', 'sphere', 'safer']),\n",
       " ('through',\n",
       "  'thro',\n",
       "  '0RGH',\n",
       "  '0R',\n",
       "  ['their', 'there', 'three', \"they're\", 'throw']),\n",
       " ('cabbage',\n",
       "  'cadig',\n",
       "  'KBG',\n",
       "  'KDG',\n",
       "  ['caddie', 'coding', 'caddis', 'cadre', 'cadet']),\n",
       " ('poisin',\n",
       "  'posin',\n",
       "  'PSN',\n",
       "  'PSN',\n",
       "  ['poison', 'posing', 'posit', 'rosin', 'posies']),\n",
       " ('pizza', 'pitzza', 'PS', 'PTS', ['pets', 'puts', 'poets', 'pots', 'pits']),\n",
       " ('use', 'yoos', 'AS', 'YS', ['yes', 'coos', 'zoos', 'yobs', 'woos']),\n",
       " ('ring', 'riag', 'RNG', 'RG', ['rug', 'reggae', 'rage', 'rouge', 'rogue']),\n",
       " ('beach', 'dech', 'B1', 'D1', ['dutch', 'ditch', 'douche', 'tech', 'deck']),\n",
       " ('want', 'wot', 'WNT', 'WT', ['what', 'white', 'weight', 'wait', 'wet']),\n",
       " ('play', 'pla', 'PLA', 'PL', ['paul', 'pool', 'poll', 'pull', 'pill']),\n",
       " ('had',\n",
       "  'haded',\n",
       "  'HD',\n",
       "  'HDD',\n",
       "  ['headed', 'hooded', 'heeded', 'shaded', 'handed']),\n",
       " ('ready', 'rete', 'RDA', 'RT', ['right', 'rate', 'write', 'wrote', 'root']),\n",
       " ('screamed',\n",
       "  'scrind',\n",
       "  'SKRMD',\n",
       "  'SKRND',\n",
       "  ['screened', 'scorned', 'scoring', 'scaring', 'screed'])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(problem_words))\n",
    "problem_words\n",
    "#for thing in problem_words:\n",
    "    #print(thing[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sort=[]\n",
    "for t in problem_words:\n",
    "    if t[2] == t[3]:\n",
    "        bad_sort.append((t[0], t[1], t[2],t[3], t[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('gills', 'gils', 'GLS', 'GLS', ['glass', 'goals', 'gals', 'gloss', 'glaze']),\n",
       " ('go on', 'gowen', 'GN', 'GN', ['gone', 'gene', 'gain', 'gun', 'guinea']),\n",
       " ('carrot',\n",
       "  'carit',\n",
       "  'KRT',\n",
       "  'KRT',\n",
       "  ['cart', 'create', 'court', 'carat', 'karate']),\n",
       " ('fell', 'fel', 'FL', 'FL', ['full', 'file', 'feel', 'follow', 'fall']),\n",
       " ('mule', 'muole', 'ML', 'ML', ['mail', 'male', 'mile', 'mall', 'mill']),\n",
       " ('fries',\n",
       "  'frice',\n",
       "  'FRS',\n",
       "  'FRS',\n",
       "  ['force', 'phrase', 'fires', 'fears', 'freeze']),\n",
       " ('dumb', 'dume', 'DM', 'DM', ['demo', 'dam', 'dom', 'doom', 'dame']),\n",
       " ('a lot',\n",
       "  'a lout',\n",
       "  'ALT',\n",
       "  'ALT',\n",
       "  ['elite', 'alt', 'alto', 'eyelet', 'allot']),\n",
       " ('soars',\n",
       "  'sors',\n",
       "  'SRS',\n",
       "  'SRS',\n",
       "  ['source', 'series', 'serious', 'zeros', 'sores']),\n",
       " ('eat', 'eta', 'AT', 'AT', ['it', 'at', 'out', 'et', 'auto']),\n",
       " ('fell', 'fel', 'FL', 'FL', ['full', 'file', 'feel', 'follow', 'fall']),\n",
       " ('fright',\n",
       "  'frait',\n",
       "  'FRT',\n",
       "  'FRT',\n",
       "  ['fort', 'fruit', 'freight', 'ferret', 'fart']),\n",
       " ('becasue',\n",
       "  'bicos',\n",
       "  'BKS',\n",
       "  'BKS',\n",
       "  ['books', 'because', 'bikes', 'bucks', 'backs']),\n",
       " ('soda', 'sode', 'SD', 'SD', ['said', 'side', 'seed', 'saudi', 'sad']),\n",
       " ('ice-cream',\n",
       "  'ice-crem',\n",
       "  'ASKRM',\n",
       "  'ASKRM',\n",
       "  ['isoform', 'scream', 'scrum', 'scrim', 'sacrum']),\n",
       " ('sled',\n",
       "  'slead',\n",
       "  'SLD',\n",
       "  'SLD',\n",
       "  ['sold', 'solid', 'slide', 'sealed', 'salad']),\n",
       " ('moose', 'mose', 'MS', 'MS', ['mass', 'miss', 'mouse', 'mice', 'mess']),\n",
       " ('sled',\n",
       "  'sleed',\n",
       "  'SLD',\n",
       "  'SLD',\n",
       "  ['sold', 'solid', 'slide', 'sealed', 'salad']),\n",
       " ('ammo', 'amoe', 'AM', 'AM', ['am', \"i'm\", 'em', 'aim', 'um']),\n",
       " ('float',\n",
       "  'flowt',\n",
       "  'FLT',\n",
       "  'FLT',\n",
       "  ['flat', 'flight', 'felt', 'fault', 'fleet']),\n",
       " ('a lot', 'allot', 'ALT', 'ALT', ['elite', 'alt', 'alto', 'eyelet', 'allot']),\n",
       " ('bell', 'bel', 'BL', 'BL', ['below', 'blue', 'bill', 'ball', 'blow']),\n",
       " ('bake', 'beick', 'BK', 'BK', ['back', 'book', 'bbc', 'bike', 'buck']),\n",
       " ('rollercoaster', 'rolrcostr', 'RLRKSTR', 'RLRKSTR', []),\n",
       " ('peanut butter', 'punat butter', 'PNTBTR', 'PNTBTR', []),\n",
       " ('tasts',\n",
       "  'tastes',\n",
       "  'TSTS',\n",
       "  'TSTS',\n",
       "  ['tests', 'tastes', 'toasts', 'tsetse', 'tasted']),\n",
       " ('fight', 'fite', 'FT', 'FT', ['photo', 'feet', 'fat', 'fit', 'foot']),\n",
       " ('fought', 'fote', 'FT', 'FT', ['photo', 'feet', 'fat', 'fit', 'foot']),\n",
       " ('tometo',\n",
       "  'tomato',\n",
       "  'TMT',\n",
       "  'TMT',\n",
       "  ['tomato', 'teammate', 'tomatoes', 'tomcat', 'automate']),\n",
       " ('flute', 'flut', 'FLT', 'FLT', ['flat', 'flight', 'felt', 'fault', 'fleet']),\n",
       " ('wheat', 'weat', 'WT', 'WT', ['what', 'white', 'weight', 'wait', 'wet']),\n",
       " ('fight', 'fite', 'FT', 'FT', ['photo', 'feet', 'fat', 'fit', 'foot']),\n",
       " ('fair', 'fer', 'FR', 'FR', ['for', 'free', 'four', 'far', 'fire']),\n",
       " ('fought', 'fot', 'FT', 'FT', ['photo', 'feet', 'fat', 'fit', 'foot']),\n",
       " ('poisin',\n",
       "  'posin',\n",
       "  'PSN',\n",
       "  'PSN',\n",
       "  ['poison', 'posing', 'posit', 'rosin', 'posies'])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(bad_sort))\n",
    "bad_sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7671568627450981"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test set\n",
    "correct = []\n",
    "problem_words = []\n",
    "for target, spelling, suggestions in zip(test[\"Target\"], test[\"Spelling\"], test[\"metaphone_suggestions\"]):\n",
    "    suggestions = suggestions [:5]\n",
    "    correct.append(target in suggestions or target.lower() in suggestions or target[0].upper() + target[1:].lower() in suggestions)\n",
    "sum_list(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44607843137254904"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TextBlob\n",
    "correct = []\n",
    "for target, suggestions in zip(test[\"Target\"], test[\"textblob_suggestions\"]):\n",
    "    suggestions = suggestions[:5]\n",
    "    correct.append(target in suggestions or target.lower() in suggestions or target[0].upper() + target[1:].lower() in suggestions)\n",
    "    \n",
    "sum_list(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7739322533136966"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Full set\n",
    "correct = []\n",
    "problem_words = []\n",
    "for target, spelling, suggestions in zip(ks[\"Target\"], ks[\"Spelling\"], ks[\"metaphone_suggestions\"]):\n",
    "    correct.append(target in suggestions or target.lower() in suggestions or target[0].upper() + target[1:].lower() in suggestions)\n",
    "         \n",
    "sum_list(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra spelling tests and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brody\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "      <th>wrong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appeal</td>\n",
       "      <td>[apeal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>employees</td>\n",
       "      <td>[emploies]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>encourage</td>\n",
       "      <td>[encorage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permanent</td>\n",
       "      <td>[perminant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mathematically</td>\n",
       "      <td>[mathematicaly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data</td>\n",
       "      <td>[dsata]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>permanently</td>\n",
       "      <td>[perminantly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hierarchal</td>\n",
       "      <td>[hierachial]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>proviso</td>\n",
       "      <td>[provisoe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>moving</td>\n",
       "      <td>[moveing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>allow</td>\n",
       "      <td>[alow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>credit</td>\n",
       "      <td>[creadit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>available</td>\n",
       "      <td>[availble]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>traditionally</td>\n",
       "      <td>[traditionaly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adaptable</td>\n",
       "      <td>[adabtable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>later</td>\n",
       "      <td>[latter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>graphically</td>\n",
       "      <td>[graphicaly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>eventually</td>\n",
       "      <td>[eventully]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>doubt</td>\n",
       "      <td>[doupt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>academically</td>\n",
       "      <td>[academicly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>subsequent</td>\n",
       "      <td>[subsequant, subsiquent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>misleading</td>\n",
       "      <td>[missleading]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ordinary</td>\n",
       "      <td>[ordenary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>associated</td>\n",
       "      <td>[assosiated]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>voluntary</td>\n",
       "      <td>[volantary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>enormously</td>\n",
       "      <td>[enomosly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>table</td>\n",
       "      <td>[tasble]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>useful</td>\n",
       "      <td>[usful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>thermawear</td>\n",
       "      <td>[thermawere, thermawhere]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>pleasant</td>\n",
       "      <td>[plesent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>between</td>\n",
       "      <td>[beeteen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>appreciation</td>\n",
       "      <td>[apreciation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>accept</td>\n",
       "      <td>[acept]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>suffering</td>\n",
       "      <td>[suufering]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>comparison</td>\n",
       "      <td>[comparrison]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>majority</td>\n",
       "      <td>[majorty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>umbrella</td>\n",
       "      <td>[umberalla]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>discipline</td>\n",
       "      <td>[disiplin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>arrangement</td>\n",
       "      <td>[arrangment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>prepared</td>\n",
       "      <td>[prepaired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>sufficient</td>\n",
       "      <td>[suficient]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>weighted</td>\n",
       "      <td>[wagted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>orientated</td>\n",
       "      <td>[orentated]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>input</td>\n",
       "      <td>[inut]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>pivoting</td>\n",
       "      <td>[pivting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>profit</td>\n",
       "      <td>[proffit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>agencies</td>\n",
       "      <td>[agences]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>accumulated</td>\n",
       "      <td>[acumulated]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>manually</td>\n",
       "      <td>[manualy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>representative</td>\n",
       "      <td>[representitive]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           correct                      wrong\n",
       "0           appeal                    [apeal]\n",
       "1        employees                 [emploies]\n",
       "2        encourage                 [encorage]\n",
       "3        permanent                [perminant]\n",
       "4   mathematically            [mathematicaly]\n",
       "5             data                    [dsata]\n",
       "6      permanently              [perminantly]\n",
       "7       hierarchal               [hierachial]\n",
       "8          proviso                 [provisoe]\n",
       "9           moving                  [moveing]\n",
       "10           allow                     [alow]\n",
       "11          credit                  [creadit]\n",
       "12       available                 [availble]\n",
       "13   traditionally             [traditionaly]\n",
       "14       adaptable                [adabtable]\n",
       "15           later                   [latter]\n",
       "16     graphically               [graphicaly]\n",
       "17      eventually                [eventully]\n",
       "18           doubt                    [doupt]\n",
       "19    academically               [academicly]\n",
       "20      subsequent   [subsequant, subsiquent]\n",
       "21      misleading              [missleading]\n",
       "22        ordinary                 [ordenary]\n",
       "23      associated               [assosiated]\n",
       "24       voluntary                [volantary]\n",
       "25      enormously                 [enomosly]\n",
       "26           table                   [tasble]\n",
       "27          useful                    [usful]\n",
       "28      thermawear  [thermawere, thermawhere]\n",
       "29        pleasant                  [plesent]\n",
       "30         between                  [beeteen]\n",
       "31    appreciation              [apreciation]\n",
       "32          accept                    [acept]\n",
       "33       suffering                [suufering]\n",
       "34      comparison              [comparrison]\n",
       "35        majority                  [majorty]\n",
       "36        umbrella                [umberalla]\n",
       "37      discipline                 [disiplin]\n",
       "38     arrangement               [arrangment]\n",
       "39        prepared                [prepaired]\n",
       "40      sufficient                [suficient]\n",
       "41        weighted                   [wagted]\n",
       "42      orientated                [orentated]\n",
       "43           input                     [inut]\n",
       "44        pivoting                  [pivting]\n",
       "45          profit                  [proffit]\n",
       "46        agencies                  [agences]\n",
       "47     accumulated               [acumulated]\n",
       "48        manually                  [manualy]\n",
       "49  representative           [representitive]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se = pd.read_csv('data/spell-testset2.txt',sep=': ', names=['correct', 'wrong'])\n",
    "se['wrong'] = se.wrong.apply(lambda x: [re.sub(r'\\*\\d', '', word).strip() for word in x.split(\" \")])\n",
    "se[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [00:03<00:00, 112.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9228650137741047\n",
      "111.26978985255695\n"
     ]
    }
   ],
   "source": [
    "# our suggestions\n",
    "corrections = []\n",
    "start=time.time()\n",
    "for correct, wrong in tqdm(zip(se[\"correct\"], se[\"wrong\"]), total=len(se[\"correct\"])):\n",
    "    wrong = wrong[0].split(\" \")\n",
    "    for w in wrong:\n",
    "        sug = metaphone_suggestions(w, 5)\n",
    "        corrections.append(correct in sug)\n",
    "end=time.time()\n",
    "print(sum_list(corrections)/len(corrections))\n",
    "print(len(se)/(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 363/363 [01:21<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7825\n",
      "4.456730027063354\n"
     ]
    }
   ],
   "source": [
    "corrections = []\n",
    "start = time.time()\n",
    "for correct, wrong in tqdm(zip(se[\"correct\"], se[\"wrong\"]), total=len(se[\"correct\"])):\n",
    "    for w in wrong:\n",
    "        sug =  [word[0] for word in Word(w).spellcheck()[0:5]]\n",
    "        #print(sug)\n",
    "        corrections.append(correct in sug)\n",
    "end=time.time()\n",
    "print(sum_list(corrections)/len(corrections))\n",
    "print(len(se)/(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Early Within Word Pattern',\n",
       " 'Early Within Word Pattern ',\n",
       " 'Early letter-Name Alphabetic',\n",
       " 'Early-Middle Letter Name Alphabetic ',\n",
       " 'Early-Middle within Word Pattern',\n",
       " 'Late Letter-Name Alphabetic',\n",
       " 'Late Syllables and Affixes',\n",
       " 'Late emergent',\n",
       " 'Late within word pattern',\n",
       " 'Letter name alphabetic',\n",
       " 'Letter-Name Alphabetic',\n",
       " 'Middle Letter Name- Alphabetic',\n",
       " 'Middle Within Word Pattern',\n",
       " 'Middle to Late Syllables and Affixes',\n",
       " 'Within Word Pattern',\n",
       " 'early Derivational Relations ',\n",
       " 'early Letter Name- Alphabetic',\n",
       " 'early Letter Name-Alphabetic',\n",
       " 'early Letter-Name Alphabetic',\n",
       " 'early Syllables and Affixes',\n",
       " 'early Syllables and Affixes ',\n",
       " 'early Within Word Pattern',\n",
       " 'early Within Word Pattern ',\n",
       " 'early derivational relations',\n",
       " 'early letter-name alphabetic',\n",
       " 'early syllables and affixes',\n",
       " 'early within word pattern',\n",
       " 'early within word patterns ',\n",
       " 'late Letter Name- Alphabetic',\n",
       " 'late Letter Name-- Alphabetic',\n",
       " 'late Syllables and Affixes',\n",
       " 'late Syllables and Affixes ',\n",
       " 'late Within Word Pattern ',\n",
       " 'late Within Word Patterns ',\n",
       " 'late Within-Word pattern',\n",
       " 'late emergent',\n",
       " 'late letter-name alphabetic',\n",
       " 'late syllables and affixes',\n",
       " 'late within word pattern ',\n",
       " 'middle Derivational Relations ',\n",
       " 'middle Letter Name-Alphabetic',\n",
       " 'middle Letter-Name Alphabetic',\n",
       " 'middle Within Word Pattern',\n",
       " 'middle Within Word Patterns ',\n",
       " 'middle letter name-alphabetic',\n",
       " 'middle letter-name alphabetic',\n",
       " 'middle syllables and affixes',\n",
       " 'middle to late within word pattern',\n",
       " 'middle within word pattern',\n",
       " 'middle within-word pattern',\n",
       " nan,\n",
       " 'within word pattern'}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ks['Level'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks[\"Level\"] = ks.Level.apply(lambda x: str(x).lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks[\"Level\"] = ks.Level.apply(lambda x: re.sub(\"-\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks[\"Level\"] = ks.Level.apply(lambda x: re.sub(\"[ ]+\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks[\"Level\"] = ks.Level.apply(lambda x: x.strip(\"s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early derivational relation',\n",
       " 'early letter name alphabetic',\n",
       " 'early middle letter name alphabetic',\n",
       " 'early middle within word pattern',\n",
       " 'early syllables and affixe',\n",
       " 'early within word pattern',\n",
       " 'late emergent',\n",
       " 'late letter name alphabetic',\n",
       " 'late syllables and affixe',\n",
       " 'late within word pattern',\n",
       " 'letter name alphabetic',\n",
       " 'middle derivational relation',\n",
       " 'middle letter name alphabetic',\n",
       " 'middle syllables and affixe',\n",
       " 'middle to late syllables and affixe',\n",
       " 'middle to late within word pattern',\n",
       " 'middle within word pattern',\n",
       " 'nan',\n",
       " 'within word pattern'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ks['Level'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = ['emergent', 'letter name', 'word pattern', 'syllables', 'derivational']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "emergent : 5 samples\n",
      "\tMetaphones: 0.8\n",
      "\tTextBlob: 0.2\n",
      "\tDifference: 0.6000000000000001\n",
      "letter name : 490 samples\n",
      "\tMetaphones: 0.763265306122449\n",
      "\tTextBlob: 0.3816326530612245\n",
      "\tDifference: 0.3816326530612245\n",
      "word pattern : 677 samples\n",
      "\tMetaphones: 0.7518463810930576\n",
      "\tTextBlob: 0.4638109305760709\n",
      "\tDifference: 0.28803545051698665\n",
      "syllables : 158 samples\n",
      "\tMetaphones: 0.8734177215189873\n",
      "\tTextBlob: 0.5316455696202531\n",
      "\tDifference: 0.3417721518987342\n",
      "derivational : 11 samples\n",
      "\tMetaphones: 0.8181818181818182\n",
      "\tTextBlob: 0.36363636363636365\n",
      "\tDifference: 0.4545454545454546\n"
     ]
    }
   ],
   "source": [
    "print(len(ks[ks[\"Level\"].str.contains(\"nan\")]))\n",
    "for level in levels:\n",
    "    sub_df = ks[ks[\"Level\"].str.contains(level)]\n",
    "    print(level, \":\", len(sub_df), \"samples\")\n",
    "    t_correct = []\n",
    "    m_correct = []\n",
    "    for target, spelling, m_suggestions, t_suggestions in zip(sub_df[\"Target\"], sub_df[\"Spelling\"], sub_df[\"metaphone_suggestions\"], sub_df[\"textblob_suggestions\"]):\n",
    "        m_correct.append(target in m_suggestions or target.lower() in m_suggestions or target[0].upper() + target[1:].lower() in m_suggestions)\n",
    "        t_correct.append(target in t_suggestions or target.lower() in t_suggestions or target[0].upper() + target[1:].lower() in t_suggestions)\n",
    "    print(\"\\tMetaphones:\",sum_list(m_correct)/len(m_correct))\n",
    "    print(\"\\tTextBlob:\",sum_list(t_correct)/len(t_correct))\n",
    "    print(\"\\tDifference:\",sum_list(m_correct)/len(m_correct) - sum_list(t_correct)/len(t_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [\n",
    "    'late emergent', \n",
    "    'early letter name alphabetic',\n",
    "    'early middle letter name alphabetic', \n",
    "    'middle letter name alphabetic',\n",
    "    'letter name alphabetic',\n",
    "    'late letter name alphabetic',\n",
    "    'early within word pattern',\n",
    "    'early middle within word pattern',\n",
    "    'middle within word pattern',\n",
    "    'within word pattern',\n",
    "    'middle to late within word pattern',\n",
    "    'late within word pattern',\n",
    "    'early syllables and affixe',\n",
    "    'middle syllables and affixe',\n",
    "    'middle to late syllables and affixe',\n",
    "    'late syllables and affixe',\n",
    "    'early derivational relation',\n",
    "    'middle derivational relation'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early letter name alphabetic : 70 samples\n",
      "\tMetaphones: 0.7285714285714285\n",
      "\tTextBlob: 0.4142857142857143\n",
      "\tDifference: 0.3142857142857142\n",
      "middle letter name alphabetic : 257 samples\n",
      "\tMetaphones: 0.754863813229572\n",
      "\tTextBlob: 0.3540856031128405\n",
      "\tDifference: 0.4007782101167315\n",
      "letter name alphabetic : 38 samples\n",
      "\tMetaphones: 0.8421052631578947\n",
      "\tTextBlob: 0.4473684210526316\n",
      "\tDifference: 0.3947368421052631\n",
      "late letter name alphabetic : 114 samples\n",
      "\tMetaphones: 0.8070175438596491\n",
      "\tTextBlob: 0.4298245614035088\n",
      "\tDifference: 0.3771929824561403\n",
      "early within word pattern : 348 samples\n",
      "\tMetaphones: 0.7442528735632183\n",
      "\tTextBlob: 0.43103448275862066\n",
      "\tDifference: 0.3132183908045977\n",
      "middle within word pattern : 227 samples\n",
      "\tMetaphones: 0.7312775330396476\n",
      "\tTextBlob: 0.4581497797356828\n",
      "\tDifference: 0.27312775330396477\n",
      "within word pattern : 20 samples\n",
      "\tMetaphones: 0.75\n",
      "\tTextBlob: 0.65\n",
      "\tDifference: 0.09999999999999998\n",
      "middle to late within word pattern : 12 samples\n",
      "\tMetaphones: 0.75\n",
      "\tTextBlob: 0.4166666666666667\n",
      "\tDifference: 0.3333333333333333\n",
      "late within word pattern : 62 samples\n",
      "\tMetaphones: 0.9193548387096774\n",
      "\tTextBlob: 0.6451612903225806\n",
      "\tDifference: 0.27419354838709675\n",
      "early syllables and affixe : 136 samples\n",
      "\tMetaphones: 0.8676470588235294\n",
      "\tTextBlob: 0.5\n",
      "\tDifference: 0.36764705882352944\n",
      "late syllables and affixe : 20 samples\n",
      "\tMetaphones: 0.9\n",
      "\tTextBlob: 0.75\n",
      "\tDifference: 0.15000000000000002\n"
     ]
    }
   ],
   "source": [
    "for level in levels:\n",
    "    sub_df = ks[ks.Level == level]\n",
    "    if len(sub_df) >= 12:\n",
    "        print(level, \":\", len(sub_df), \"samples\")\n",
    "        t_correct = []\n",
    "        m_correct = []\n",
    "        for target, spelling, m_suggestions, t_suggestions in zip(sub_df[\"Target\"], sub_df[\"Spelling\"], sub_df[\"metaphone_suggestions\"], sub_df[\"textblob_suggestions\"]):\n",
    "            m_correct.append(target in m_suggestions or target.lower() in m_suggestions or target[0].upper() + target[1:].lower() in m_suggestions)\n",
    "            t_correct.append(target in t_suggestions or target.lower() in t_suggestions or target[0].upper() + target[1:].lower() in t_suggestions)\n",
    "        print(\"\\tMetaphones:\",sum_list(m_correct)/len(m_correct))\n",
    "        print(\"\\tTextBlob:\",sum_list(t_correct)/len(t_correct))\n",
    "        print(\"\\tDifference:\",sum_list(m_correct)/len(m_correct) - sum_list(t_correct)/len(t_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1', '2', '3', '4', '5', '6', '7', '8', 'k', nan}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(ks['Grade'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k : 15 samples\n",
      "\tMetaphones: 0.7333333333333333\n",
      "\tTextBlob: 0.4666666666666667\n",
      "\tDifference: 0.2666666666666666\n",
      "1 : 144 samples\n",
      "\tMetaphones: 0.6458333333333334\n",
      "\tTextBlob: 0.3402777777777778\n",
      "\tDifference: 0.3055555555555556\n",
      "2 : 386 samples\n",
      "\tMetaphones: 0.7461139896373057\n",
      "\tTextBlob: 0.4170984455958549\n",
      "\tDifference: 0.3290155440414508\n",
      "3 : 277 samples\n",
      "\tMetaphones: 0.8122743682310469\n",
      "\tTextBlob: 0.44765342960288806\n",
      "\tDifference: 0.36462093862815886\n",
      "4 : 315 samples\n",
      "\tMetaphones: 0.7841269841269841\n",
      "\tTextBlob: 0.46984126984126984\n",
      "\tDifference: 0.3142857142857143\n",
      "5 : 95 samples\n",
      "\tMetaphones: 0.8421052631578947\n",
      "\tTextBlob: 0.5052631578947369\n",
      "\tDifference: 0.33684210526315783\n",
      "6 : 44 samples\n",
      "\tMetaphones: 0.7954545454545454\n",
      "\tTextBlob: 0.5227272727272727\n",
      "\tDifference: 0.2727272727272727\n",
      "7 : 44 samples\n",
      "\tMetaphones: 0.8409090909090909\n",
      "\tTextBlob: 0.5227272727272727\n",
      "\tDifference: 0.31818181818181823\n",
      "8 : 21 samples\n",
      "\tMetaphones: 0.8571428571428571\n",
      "\tTextBlob: 0.3333333333333333\n",
      "\tDifference: 0.5238095238095237\n"
     ]
    }
   ],
   "source": [
    "for grade in ['k','1', '2', '3', '4', '5', '6', '7', '8']:\n",
    "    sub_df = ks[ks.Grade == grade]\n",
    "    print(grade, \":\", len(sub_df), \"samples\")\n",
    "    t_correct = []\n",
    "    m_correct = []\n",
    "    for target, spelling, m_suggestions, t_suggestions in zip(sub_df[\"Target\"], sub_df[\"Spelling\"], sub_df[\"metaphone_suggestions\"], sub_df[\"textblob_suggestions\"]):\n",
    "        m_correct.append(target in m_suggestions or target.lower() in m_suggestions or target[0].upper() + target[1:].lower() in m_suggestions)\n",
    "        t_correct.append(target in t_suggestions or target.lower() in t_suggestions or target[0].upper() + target[1:].lower() in t_suggestions)\n",
    "    print(\"\\tMetaphones:\",sum_list(m_correct)/len(m_correct))\n",
    "    print(\"\\tTextBlob:\",sum_list(t_correct)/len(t_correct))\n",
    "    print(\"\\tDifference:\",sum_list(m_correct)/len(m_correct) - sum_list(t_correct)/len(t_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = set([len(word) for word in ks['Target'].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : 50 samples\n",
      "\tMetaphones: 0.84\n",
      "\tTextBlob: 0.18\n",
      "\tDifference: 0.6599999999999999\n",
      "3 : 79 samples\n",
      "\tMetaphones: 0.7341772151898734\n",
      "\tTextBlob: 0.43037974683544306\n",
      "\tDifference: 0.3037974683544304\n",
      "4 : 281 samples\n",
      "\tMetaphones: 0.7864768683274022\n",
      "\tTextBlob: 0.4626334519572954\n",
      "\tDifference: 0.3238434163701068\n",
      "5 : 318 samples\n",
      "\tMetaphones: 0.7421383647798742\n",
      "\tTextBlob: 0.4276729559748428\n",
      "\tDifference: 0.3144654088050314\n",
      "6 : 217 samples\n",
      "\tMetaphones: 0.7695852534562212\n",
      "\tTextBlob: 0.4608294930875576\n",
      "\tDifference: 0.3087557603686636\n",
      "7 : 208 samples\n",
      "\tMetaphones: 0.7548076923076923\n",
      "\tTextBlob: 0.5096153846153846\n",
      "\tDifference: 0.2451923076923077\n",
      "8 : 90 samples\n",
      "\tMetaphones: 0.8555555555555555\n",
      "\tTextBlob: 0.45555555555555555\n",
      "\tDifference: 0.39999999999999997\n",
      "9 : 77 samples\n",
      "\tMetaphones: 0.9090909090909091\n",
      "\tTextBlob: 0.37662337662337664\n",
      "\tDifference: 0.5324675324675324\n",
      "10 : 20 samples\n",
      "\tMetaphones: 0.75\n",
      "\tTextBlob: 0.4\n",
      "\tDifference: 0.35\n"
     ]
    }
   ],
   "source": [
    "for length in lengths:\n",
    "    sub_df = ks[ks[\"Target\"].str.len() == length]\n",
    "    if len(sub_df) >= 10:\n",
    "        print(length, \":\", len(sub_df), \"samples\")\n",
    "        t_correct = []\n",
    "        m_correct = []\n",
    "        for target, spelling, m_suggestions, t_suggestions in zip(sub_df[\"Target\"], sub_df[\"Spelling\"], sub_df[\"metaphone_suggestions\"], sub_df[\"textblob_suggestions\"]):\n",
    "            m_correct.append(target in m_suggestions or target.lower() in m_suggestions or target[0].upper() + target[1:].lower() in m_suggestions)\n",
    "            t_correct.append(target in t_suggestions or target.lower() in t_suggestions or target[0].upper() + target[1:].lower() in t_suggestions)\n",
    "        print(\"\\tMetaphones:\",sum_list(m_correct)/len(m_correct))\n",
    "        print(\"\\tTextBlob:\",sum_list(t_correct)/len(t_correct))\n",
    "        print(\"\\tDifference:\",sum_list(m_correct)/len(m_correct) - sum_list(t_correct)/len(t_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Spelling</th>\n",
       "      <th>Level</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>metaphone_suggestions</th>\n",
       "      <th>textblob_suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>favorite</td>\n",
       "      <td>favtit</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[favorite, favourite]</td>\n",
       "      <td>[fait]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>villager</td>\n",
       "      <td>villajg</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[village, valuing, voltage]</td>\n",
       "      <td>[village, villain, villa, villas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>exploded</td>\n",
       "      <td>xspladed</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[suspended]</td>\n",
       "      <td>[xspladed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>probably</td>\n",
       "      <td>probly</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[probably, problem, proudly, probity, poorly]</td>\n",
       "      <td>[probably, problem, probe, proudly, portly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>infinite</td>\n",
       "      <td>infinit</td>\n",
       "      <td>middle within word pattern</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[infant, infinite, infante, infinity, infinitive]</td>\n",
       "      <td>[infinite, infinity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>computer</td>\n",
       "      <td>cumpiter</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[computer, sumpter, compiler, computers, compo...</td>\n",
       "      <td>[computer, jupiter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>screamed</td>\n",
       "      <td>scrind</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[screened, scorned, scoring, scaring, screed]</td>\n",
       "      <td>[cried, spring, string, shrine, strand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>favorite</td>\n",
       "      <td>favurite</td>\n",
       "      <td>middle letter name alphabetic</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[favorite, favourite, favourites, favorites, f...</td>\n",
       "      <td>[favorite, favourite]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>lollipop</td>\n",
       "      <td>lolipop</td>\n",
       "      <td>middle letter name alphabetic</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[lollipop, lollipops, lilliput]</td>\n",
       "      <td>[lolipop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>question</td>\n",
       "      <td>quasion</td>\n",
       "      <td>middle within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[equation, question, fusion, quotation, tuition]</td>\n",
       "      <td>[question, fusion, quasi, equation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>composed</td>\n",
       "      <td>compoused</td>\n",
       "      <td>middle within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[composed, composted, composer, composes, comp...</td>\n",
       "      <td>[composed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>favorite</td>\n",
       "      <td>faviort</td>\n",
       "      <td>early syllables and affixe</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[favorite, favourite, favor, flirt, avert]</td>\n",
       "      <td>[favor, favors, savior]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>whatever</td>\n",
       "      <td>watever</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[whatever, waiver, whoever, waver, water]</td>\n",
       "      <td>[whatever]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>spitting</td>\n",
       "      <td>spiting</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[spotting, spitting, spouting, siting, suiting]</td>\n",
       "      <td>[spitting, spiking]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>anywhere</td>\n",
       "      <td>anywear</td>\n",
       "      <td>middle within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[answer, anyway, anywhere, rainwear, anyways]</td>\n",
       "      <td>[answer, anyway]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>universe</td>\n",
       "      <td>univeres</td>\n",
       "      <td>middle within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[universe, inverse, universes, universal, inve...</td>\n",
       "      <td>[universe, univers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>vacation</td>\n",
       "      <td>vacashin</td>\n",
       "      <td>middle within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[vacation, vocation, vacations, evacuation, oc...</td>\n",
       "      <td>[vacashin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>going to</td>\n",
       "      <td>gunn</td>\n",
       "      <td>middle within word pattern</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[gone, gene, gain, gun, guinea]</td>\n",
       "      <td>[guns, gun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>revision</td>\n",
       "      <td>revisen</td>\n",
       "      <td>early syllables and affixe</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[revise, revises, revised, revising, revision]</td>\n",
       "      <td>[revised, revise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>happened</td>\n",
       "      <td>hapened</td>\n",
       "      <td>early syllables and affixe</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[happened, ripened, opened, reopened, deepened]</td>\n",
       "      <td>[happened]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>pictures</td>\n",
       "      <td>pitchers</td>\n",
       "      <td>early syllables and affixe</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[pitchers, poachers, pitcher, pitches, watchers]</td>\n",
       "      <td>[pitcher]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>happened</td>\n",
       "      <td>hapened</td>\n",
       "      <td>early syllables and affixe</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[happened, ripened, opened, reopened, deepened]</td>\n",
       "      <td>[happened]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>obstacle</td>\n",
       "      <td>opsticol</td>\n",
       "      <td>middle within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[optical, acoustical, apolitical, obstacle, up...</td>\n",
       "      <td>[optical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>exciting</td>\n",
       "      <td>igsiting</td>\n",
       "      <td>middle within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[inciting, digesting, assisting, ingesting, ex...</td>\n",
       "      <td>[inviting, visiting, insisting, inditing, inci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>everyone</td>\n",
       "      <td>everwone</td>\n",
       "      <td>early letter name alphabetic</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[everyone, overtone, overdone, aversion, overrun]</td>\n",
       "      <td>[everyone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>everyone</td>\n",
       "      <td>everwone</td>\n",
       "      <td>early letter name alphabetic</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[everyone, overtone, overdone, aversion, overrun]</td>\n",
       "      <td>[everyone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>upstairs</td>\n",
       "      <td>up stars</td>\n",
       "      <td>early letter name alphabetic</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[upstairs, upstarts, upstart, posters, pastors]</td>\n",
       "      <td>[upstairs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>upstairs</td>\n",
       "      <td>upstars</td>\n",
       "      <td>early letter name alphabetic</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[upstairs, upstarts, upstart, hipsters, oysters]</td>\n",
       "      <td>[upstairs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>favorite</td>\n",
       "      <td>fivret</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[favorite, favourite, ferret, fret, fiver]</td>\n",
       "      <td>[first, five, fire, fibres, fires]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>standing</td>\n",
       "      <td>stending</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[standing, sending, tending, spending, attending]</td>\n",
       "      <td>[standing, sending, spending, tending]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>wondered</td>\n",
       "      <td>wonderd</td>\n",
       "      <td>early syllables and affixe</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[wondered, wandered, wonders, wonder, pondered]</td>\n",
       "      <td>[wonder, wondered, wonders]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>funniest</td>\n",
       "      <td>funnyest</td>\n",
       "      <td>early syllables and affixe</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[finest, funniest, funnies, fannies, faintest]</td>\n",
       "      <td>[funniest]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>saturday</td>\n",
       "      <td>sodrday</td>\n",
       "      <td>late letter name alphabetic</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[saturday, sturdy]</td>\n",
       "      <td>[someday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>practice</td>\n",
       "      <td>pratis</td>\n",
       "      <td>late letter name alphabetic</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[parts, parties, ports, pirates, protease]</td>\n",
       "      <td>[parts, parties, paris, rates, praise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>favorite</td>\n",
       "      <td>favrit</td>\n",
       "      <td>late letter name alphabetic</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[favorite, favourite, fart, favorites, favouri...</td>\n",
       "      <td>[favorite, fait, fabric, gavril]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>scorpion</td>\n",
       "      <td>scorpen</td>\n",
       "      <td>late within word pattern</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[scorpion, screen, scorn, scorpions, scrapes]</td>\n",
       "      <td>[score, screen, scope, scorn, scored]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>licorice</td>\n",
       "      <td>likrorish</td>\n",
       "      <td>early letter name alphabetic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[likrorish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>favorite</td>\n",
       "      <td>favrite</td>\n",
       "      <td>middle within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[favorite, favourite, favorites, ferrite, favo...</td>\n",
       "      <td>[favorite]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>colorful</td>\n",
       "      <td>calrful</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[colorful, careful, clerical, chlorophyll, cla...</td>\n",
       "      <td>[careful, caseful, baleful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>friendly</td>\n",
       "      <td>frenly</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[freely, frenzy, friendly, firefly, frankly]</td>\n",
       "      <td>[freely, frenzy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>suddenly</td>\n",
       "      <td>suddently</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[suddenly, silently, accidently, decently, sed...</td>\n",
       "      <td>[suddenly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>creature</td>\n",
       "      <td>crecher</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[creature, creche, cruncher, preacher, crochet]</td>\n",
       "      <td>[richer, beecher, preacher, becher, catcher]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>climbing</td>\n",
       "      <td>climing</td>\n",
       "      <td>within word pattern</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[claiming, calming, climbing, liming, clicking]</td>\n",
       "      <td>[claiming, climbing, chiming]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>colorful</td>\n",
       "      <td>colerful</td>\n",
       "      <td>within word pattern</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[colorful, careful, clerical, clarify, chlorop...</td>\n",
       "      <td>[powerful, cheerful, doleful, colourful]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>dolphins</td>\n",
       "      <td>dolfins</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dolphins, defines, dolphin, deletions, delusi...</td>\n",
       "      <td>[dolens, doffing, collins]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>dolphins</td>\n",
       "      <td>dolfins</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dolphins, defines, dolphin, deletions, delusi...</td>\n",
       "      <td>[dolens, doffing, collins]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>everyone</td>\n",
       "      <td>evrewan</td>\n",
       "      <td>early within word pattern</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[everyone, ovarian, overrun, everyman, even]</td>\n",
       "      <td>[evrewan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>potatoes</td>\n",
       "      <td>putatos</td>\n",
       "      <td>letter name alphabetic</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[potatoes, petites, potato, putts, putative]</td>\n",
       "      <td>[potatoes, potato]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>watching</td>\n",
       "      <td>woching</td>\n",
       "      <td>letter name alphabetic</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[watching, witching, notching, touching, poach...</td>\n",
       "      <td>[nothing, wishing, working, watching, touching]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>princess</td>\n",
       "      <td>priins</td>\n",
       "      <td>middle letter name alphabetic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[prince, prawns, prunes, prunus, sprains]</td>\n",
       "      <td>[print, prices, pains, trains, reins]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>going to</td>\n",
       "      <td>goeto</td>\n",
       "      <td>middle letter name alphabetic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[get, got, gate, goat, ghetto]</td>\n",
       "      <td>[goeth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>save her</td>\n",
       "      <td>safr</td>\n",
       "      <td>middle letter name alphabetic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[safari, suffer, sapphire, sphere, safer]</td>\n",
       "      <td>[safe, safer, safi, saar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>presents</td>\n",
       "      <td>pisits</td>\n",
       "      <td>middle letter name alphabetic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[posts, pests, pastas, pastes, posits]</td>\n",
       "      <td>[visits]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>vampires</td>\n",
       "      <td>vapirs</td>\n",
       "      <td>early middle letter name alphabetic</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[vipers, vapours, vampires, tapers, varies]</td>\n",
       "      <td>[papers, varies, hairs, pairs, tapers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>werewolf</td>\n",
       "      <td>welf wof</td>\n",
       "      <td>early middle letter name alphabetic</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[welf wof]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>versions</td>\n",
       "      <td>versons</td>\n",
       "      <td>late within word pattern</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[versions, persons, personas, versus, verses]</td>\n",
       "      <td>[persons, versions, verrons]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>standard</td>\n",
       "      <td>standered</td>\n",
       "      <td>late within word pattern</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[standard, squandered, tendered, standards, st...</td>\n",
       "      <td>[slandered]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>electric</td>\n",
       "      <td>eletric</td>\n",
       "      <td>late within word pattern</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[electric, esoteric, enteric, allosteric, elec...</td>\n",
       "      <td>[electric]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>favorite</td>\n",
       "      <td>favrot</td>\n",
       "      <td>late within word pattern</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[favorite, favourite, fart, favor, favorites]</td>\n",
       "      <td>[favor, favors, parrot, carrot, faro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>uniforms</td>\n",
       "      <td>informs</td>\n",
       "      <td>middle syllables and affixe</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[uniforms, informs, inform, informer, informal]</td>\n",
       "      <td>[informs]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Target   Spelling                                Level Grade  \\\n",
       "0     favorite     favtit            early within word pattern     1   \n",
       "5     villager    villajg            early within word pattern     1   \n",
       "23    exploded   xspladed            early within word pattern     1   \n",
       "32    probably     probly            early within word pattern     1   \n",
       "47    infinite    infinit           middle within word pattern     2   \n",
       "65    computer   cumpiter            early within word pattern     2   \n",
       "74    screamed     scrind            early within word pattern     2   \n",
       "146   favorite   favurite        middle letter name alphabetic     2   \n",
       "220   lollipop    lolipop        middle letter name alphabetic     2   \n",
       "276   question    quasion           middle within word pattern     3   \n",
       "277   composed  compoused           middle within word pattern     3   \n",
       "300   favorite    faviort           early syllables and affixe     3   \n",
       "335   whatever    watever            early within word pattern     3   \n",
       "394   spitting    spiting            early within word pattern     3   \n",
       "409   anywhere    anywear           middle within word pattern     3   \n",
       "410   universe   univeres           middle within word pattern     3   \n",
       "414   vacation   vacashin           middle within word pattern     3   \n",
       "420   going to       gunn           middle within word pattern     4   \n",
       "453   revision    revisen           early syllables and affixe     4   \n",
       "462   happened    hapened           early syllables and affixe     4   \n",
       "467   pictures   pitchers           early syllables and affixe     4   \n",
       "470   happened    hapened           early syllables and affixe     4   \n",
       "481   obstacle   opsticol           middle within word pattern     3   \n",
       "498   exciting   igsiting           middle within word pattern     3   \n",
       "537   everyone   everwone         early letter name alphabetic     6   \n",
       "540   everyone   everwone         early letter name alphabetic     6   \n",
       "548   upstairs   up stars         early letter name alphabetic     6   \n",
       "549   upstairs    upstars         early letter name alphabetic     6   \n",
       "569   favorite     fivret            early within word pattern     4   \n",
       "574   standing   stending            early within word pattern     4   \n",
       "...        ...        ...                                  ...   ...   \n",
       "959   wondered    wonderd           early syllables and affixe     5   \n",
       "960   funniest   funnyest           early syllables and affixe     5   \n",
       "986   saturday    sodrday          late letter name alphabetic     2   \n",
       "989   practice     pratis          late letter name alphabetic     2   \n",
       "1004  favorite     favrit          late letter name alphabetic     2   \n",
       "1026  scorpion    scorpen             late within word pattern     4   \n",
       "1037  licorice  likrorish         early letter name alphabetic     1   \n",
       "1145  favorite    favrite           middle within word pattern     3   \n",
       "1170  colorful    calrful            early within word pattern     3   \n",
       "1171  friendly     frenly            early within word pattern     3   \n",
       "1178  suddenly  suddently            early within word pattern     3   \n",
       "1179  creature    crecher            early within word pattern     3   \n",
       "1208  climbing    climing                  within word pattern     2   \n",
       "1217  colorful   colerful                  within word pattern     2   \n",
       "1226  dolphins    dolfins            early within word pattern     2   \n",
       "1227  dolphins    dolfins            early within word pattern     2   \n",
       "1261  everyone    evrewan            early within word pattern     3   \n",
       "1288  potatoes    putatos               letter name alphabetic     4   \n",
       "1311  watching    woching               letter name alphabetic     4   \n",
       "1321  princess     priins        middle letter name alphabetic     1   \n",
       "1324  going to      goeto        middle letter name alphabetic     1   \n",
       "1325  save her       safr        middle letter name alphabetic     1   \n",
       "1329  presents     pisits        middle letter name alphabetic     1   \n",
       "1339  vampires     vapirs  early middle letter name alphabetic     2   \n",
       "1342  werewolf   welf wof  early middle letter name alphabetic     2   \n",
       "1348  versions    versons             late within word pattern     8   \n",
       "1349  standard  standered             late within word pattern     8   \n",
       "1350  electric    eletric             late within word pattern     8   \n",
       "1352  favorite     favrot             late within word pattern     8   \n",
       "1362  uniforms    informs          middle syllables and affixe     6   \n",
       "\n",
       "     Unnamed: 6                              metaphone_suggestions  \\\n",
       "0           NaN                              [favorite, favourite]   \n",
       "5           NaN                        [village, valuing, voltage]   \n",
       "23          NaN                                        [suspended]   \n",
       "32          NaN      [probably, problem, proudly, probity, poorly]   \n",
       "47          NaN  [infant, infinite, infante, infinity, infinitive]   \n",
       "65          NaN  [computer, sumpter, compiler, computers, compo...   \n",
       "74          NaN      [screened, scorned, scoring, scaring, screed]   \n",
       "146         NaN  [favorite, favourite, favourites, favorites, f...   \n",
       "220         NaN                    [lollipop, lollipops, lilliput]   \n",
       "276         NaN   [equation, question, fusion, quotation, tuition]   \n",
       "277         NaN  [composed, composted, composer, composes, comp...   \n",
       "300         NaN         [favorite, favourite, favor, flirt, avert]   \n",
       "335         NaN          [whatever, waiver, whoever, waver, water]   \n",
       "394         NaN    [spotting, spitting, spouting, siting, suiting]   \n",
       "409         NaN      [answer, anyway, anywhere, rainwear, anyways]   \n",
       "410         NaN  [universe, inverse, universes, universal, inve...   \n",
       "414         NaN  [vacation, vocation, vacations, evacuation, oc...   \n",
       "420         NaN                    [gone, gene, gain, gun, guinea]   \n",
       "453         NaN     [revise, revises, revised, revising, revision]   \n",
       "462         NaN    [happened, ripened, opened, reopened, deepened]   \n",
       "467         NaN   [pitchers, poachers, pitcher, pitches, watchers]   \n",
       "470         NaN    [happened, ripened, opened, reopened, deepened]   \n",
       "481         NaN  [optical, acoustical, apolitical, obstacle, up...   \n",
       "498         NaN  [inciting, digesting, assisting, ingesting, ex...   \n",
       "537         NaN  [everyone, overtone, overdone, aversion, overrun]   \n",
       "540         NaN  [everyone, overtone, overdone, aversion, overrun]   \n",
       "548         NaN    [upstairs, upstarts, upstart, posters, pastors]   \n",
       "549         NaN   [upstairs, upstarts, upstart, hipsters, oysters]   \n",
       "569         NaN         [favorite, favourite, ferret, fret, fiver]   \n",
       "574         NaN  [standing, sending, tending, spending, attending]   \n",
       "...         ...                                                ...   \n",
       "959         NaN    [wondered, wandered, wonders, wonder, pondered]   \n",
       "960         NaN     [finest, funniest, funnies, fannies, faintest]   \n",
       "986         NaN                                 [saturday, sturdy]   \n",
       "989         NaN         [parts, parties, ports, pirates, protease]   \n",
       "1004        NaN  [favorite, favourite, fart, favorites, favouri...   \n",
       "1026        NaN      [scorpion, screen, scorn, scorpions, scrapes]   \n",
       "1037        NaN                                                 []   \n",
       "1145        NaN  [favorite, favourite, favorites, ferrite, favo...   \n",
       "1170        NaN  [colorful, careful, clerical, chlorophyll, cla...   \n",
       "1171        NaN       [freely, frenzy, friendly, firefly, frankly]   \n",
       "1178        NaN  [suddenly, silently, accidently, decently, sed...   \n",
       "1179        NaN    [creature, creche, cruncher, preacher, crochet]   \n",
       "1208        NaN    [claiming, calming, climbing, liming, clicking]   \n",
       "1217        NaN  [colorful, careful, clerical, clarify, chlorop...   \n",
       "1226        NaN  [dolphins, defines, dolphin, deletions, delusi...   \n",
       "1227        NaN  [dolphins, defines, dolphin, deletions, delusi...   \n",
       "1261        NaN       [everyone, ovarian, overrun, everyman, even]   \n",
       "1288        NaN       [potatoes, petites, potato, putts, putative]   \n",
       "1311        NaN  [watching, witching, notching, touching, poach...   \n",
       "1321        NaN          [prince, prawns, prunes, prunus, sprains]   \n",
       "1324        NaN                     [get, got, gate, goat, ghetto]   \n",
       "1325        NaN          [safari, suffer, sapphire, sphere, safer]   \n",
       "1329        NaN             [posts, pests, pastas, pastes, posits]   \n",
       "1339        NaN        [vipers, vapours, vampires, tapers, varies]   \n",
       "1342        NaN                                                 []   \n",
       "1348        NaN      [versions, persons, personas, versus, verses]   \n",
       "1349        NaN  [standard, squandered, tendered, standards, st...   \n",
       "1350        NaN  [electric, esoteric, enteric, allosteric, elec...   \n",
       "1352        NaN      [favorite, favourite, fart, favor, favorites]   \n",
       "1362        NaN    [uniforms, informs, inform, informer, informal]   \n",
       "\n",
       "                                   textblob_suggestions  \n",
       "0                                                [fait]  \n",
       "5                     [village, villain, villa, villas]  \n",
       "23                                           [xspladed]  \n",
       "32          [probably, problem, probe, proudly, portly]  \n",
       "47                                 [infinite, infinity]  \n",
       "65                                  [computer, jupiter]  \n",
       "74              [cried, spring, string, shrine, strand]  \n",
       "146                               [favorite, favourite]  \n",
       "220                                           [lolipop]  \n",
       "276                 [question, fusion, quasi, equation]  \n",
       "277                                          [composed]  \n",
       "300                             [favor, favors, savior]  \n",
       "335                                          [whatever]  \n",
       "394                                 [spitting, spiking]  \n",
       "409                                    [answer, anyway]  \n",
       "410                                 [universe, univers]  \n",
       "414                                          [vacashin]  \n",
       "420                                         [guns, gun]  \n",
       "453                                   [revised, revise]  \n",
       "462                                          [happened]  \n",
       "467                                           [pitcher]  \n",
       "470                                          [happened]  \n",
       "481                                           [optical]  \n",
       "498   [inviting, visiting, insisting, inditing, inci...  \n",
       "537                                          [everyone]  \n",
       "540                                          [everyone]  \n",
       "548                                          [upstairs]  \n",
       "549                                          [upstairs]  \n",
       "569                  [first, five, fire, fibres, fires]  \n",
       "574              [standing, sending, spending, tending]  \n",
       "...                                                 ...  \n",
       "959                         [wonder, wondered, wonders]  \n",
       "960                                          [funniest]  \n",
       "986                                           [someday]  \n",
       "989              [parts, parties, paris, rates, praise]  \n",
       "1004                   [favorite, fait, fabric, gavril]  \n",
       "1026              [score, screen, scope, scorn, scored]  \n",
       "1037                                        [likrorish]  \n",
       "1145                                         [favorite]  \n",
       "1170                        [careful, caseful, baleful]  \n",
       "1171                                   [freely, frenzy]  \n",
       "1178                                         [suddenly]  \n",
       "1179       [richer, beecher, preacher, becher, catcher]  \n",
       "1208                      [claiming, climbing, chiming]  \n",
       "1217           [powerful, cheerful, doleful, colourful]  \n",
       "1226                         [dolens, doffing, collins]  \n",
       "1227                         [dolens, doffing, collins]  \n",
       "1261                                          [evrewan]  \n",
       "1288                                 [potatoes, potato]  \n",
       "1311    [nothing, wishing, working, watching, touching]  \n",
       "1321              [print, prices, pains, trains, reins]  \n",
       "1324                                            [goeth]  \n",
       "1325                          [safe, safer, safi, saar]  \n",
       "1329                                           [visits]  \n",
       "1339             [papers, varies, hairs, pairs, tapers]  \n",
       "1342                                         [welf wof]  \n",
       "1348                       [persons, versions, verrons]  \n",
       "1349                                        [slandered]  \n",
       "1350                                         [electric]  \n",
       "1352              [favor, favors, parrot, carrot, faro]  \n",
       "1362                                          [informs]  \n",
       "\n",
       "[90 rows x 7 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks[ks[\"Target\"].str.len() == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageLen(lst):\n",
    "    lengths = [len(i) for i in lst]\n",
    "    return 0 if len(lengths) == 0 else (float(sum(lengths)) / len(lengths)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ks[\"metaphone_suggestions\"].tolist()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(i) for i in ks[\"metaphone_suggestions\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.924889543446245"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averageLen(ks[\"metaphone_suggestions\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0537555228276876"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averageLen(ks[\"textblob_suggestions\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
